{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_Llama/blob/main/ExemploRespondendoPerguntaTextoLongo_Llama2_Langchain_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Respondendo Perguntas sobre Textos Longos usando Llama v2.0, Longchain, Chroma e Transformers by HuggingFace\n",
        "\n",
        "**Toda a execução ocorre no Google Colaboratory.**\n",
        "\n",
        "Pré-requisitos:\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "- Configurar o notebook para usar GPU- Acesse o menu 'Ambiente de Execução -> Alterar o tipo do ambiente de execução -> Acelerador de hardware -> T4 GPU\n",
        "\n",
        "\n",
        "**Referências**\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed\n",
        "\n",
        "**Lista dos modelos:**\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "## Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "outputs": [],
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "outputs": [],
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmhxcvIfbG2"
      },
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603LYIYKBmq5"
      },
      "source": [
        "Função auxiliar para formatar o tempo como `hh: mm: ss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guy6B4whsZFR"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas.\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def formataTempo(tempo):\n",
        "    \"\"\"\n",
        "      Pega a tempo em segundos e retorna uma string hh:mm:ss\n",
        "    \"\"\"\n",
        "    # Arredonda para o segundo mais próximo.\n",
        "    tempo_arredondado = int(round((tempo)))\n",
        "\n",
        "    # Formata como hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=tempo_arredondado))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprime linhas menores."
      ],
      "metadata": {
        "id": "V1vu-ch8yT5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_linhas_menores(texto, tamanho=120):\n",
        "  for i in range(0, len(texto), tamanho):\n",
        "    print(texto[i:i+tamanho])"
      ],
      "metadata": {
        "id": "8BKQZtF9yUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 1 - Instalação das bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteca para manipular pdf"
      ],
      "metadata": {
        "id": "akFHj1OT0eCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf==3.16.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mdrRBD_0gAL",
        "outputId": "a689c971-59f7-4aee-b28f-fc3fc774d0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf==3.16.4 in /usr/local/lib/python3.10/dist-packages (3.16.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependência para manipular os embeddings pelo Langchain"
      ],
      "metadata": {
        "id": "IHKbYosXal6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers==2.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQYsLbh1aoEe",
        "outputId": "c5fa459b-77bf-4151-b804-d55fcda0a402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers==2.2.2) (12.3.52)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers==2.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\n",
            "Collecting torch>=1.6.0 (from sentence_transformers==2.2.2)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers==2.2.2) (9.4.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2) (0.41.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers==2.2.2) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers==2.2.2) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0\n",
            "    Uninstalling torch-2.1.0:\n",
            "      Successfully uninstalled torch-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.22.post4 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instala o Chroma para armazenar os embeddings"
      ],
      "metadata": {
        "id": "xX6UfQIXbZGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.4.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQKufOHtbbAc",
        "outputId": "1c0bab5a-1494-4160-f44f-3d38fd13522b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb==0.4.15 in /usr/local/lib/python3.10/dist-packages (0.4.15)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.10.13)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.104.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.23.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (4.8.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.16.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.13.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (6.1.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.59.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (4.0.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (28.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (8.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.23.5)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.4.15) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.4.15) (0.27.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (6.0.1)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.6.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (3.2.2)\n",
            "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.26.18)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (6.8.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.61.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.20.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.20.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.41b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.15) (0.41b0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.15) (1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.15) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.15) (3.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.4.15) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb==0.4.15) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb==0.4.15) (1.1.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.15) (3.17.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.15) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instala langchain"
      ],
      "metadata": {
        "id": "PGrlTKgSLdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.0.321"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppVeArJcLdVb",
        "outputId": "8af3729d-cc4b-4ce0-8a0e-646a8950c7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.0.321 in /usr/local/lib/python3.10/dist-packages (0.0.321)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (0.0.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.321) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.321) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.321) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.321) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.321) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.321) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.321) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.321) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.321) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.321) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.321) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.321) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.321) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.321) (4.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.321) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.321) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.321) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.321) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.321) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependências do xformers"
      ],
      "metadata": {
        "id": "upho_jty-L2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb\n",
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 torchtext==0.15.2+cpu torchdata==0.6.1 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "VgO9dhZX66Va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa19438a-f004-4ef6-a041-1b878b973233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "Requirement already satisfied: torchvision==0.15.2+cu118 in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: torchtext==0.15.2+cpu in /usr/local/lib/python3.10/dist-packages (0.15.2+cpu)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2+cpu) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1) (1.26.18)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cu118) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.22.post4 requires torch==2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permite maior velocidade e menor consumo de memória nos transformers."
      ],
      "metadata": {
        "id": "bDqzuP1kqPZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers==0.0.22.post4"
      ],
      "metadata": {
        "id": "Evr5Vtp0qWE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4277516-7ec5-45d5-f4e1-0c1eced37ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers==0.0.22.post4 in /usr/local/lib/python3.10/dist-packages (0.0.22.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.22.post4) (1.23.5)\n",
            "Collecting torch==2.1.0 (from xformers==0.0.22.post4)\n",
            "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post4) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->xformers==0.0.22.post4)\n",
            "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers==0.0.22.post4) (12.3.52)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers==0.0.22.post4) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers==0.0.22.post4) (1.3.0)\n",
            "Installing collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.15.2+cpu requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0 triton-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0jVfo3QM3h"
      },
      "source": [
        "O bitsandbytes é um wrapper leve em torno de funções personalizadas CUDA, em particular otimizadores de 8 bits, multiplicação de matrizes (LLM.int8()) e funções de quantização. É uma dependência do accelerate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12GE2W3fQM_n",
        "outputId": "59c919d1-726c-411e-eb72-c63d6ccfc4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes==0.41.1 in /usr/local/lib/python3.10/dist-packages (0.41.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes==0.41.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wU6vuyAuPd"
      },
      "source": [
        "Accelerate é uma biblioteca que permite que o mesmo código PyTorch seja executado em qualquer configuração distribuída adicionando apenas quatro linhas de código. Otimiza as operações do PyTorch, especialmente na GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTMID1rZAvx7",
        "outputId": "e7f69f3f-2530-4236-fb4f-1dbd1b53ba66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==0.23.0 in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.23.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.23.0) (12.3.52)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.23.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.23.0) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.23.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.23.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.23.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.23.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.23.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# accelerate: treino distribuído, mixed precision, consumer hardware\n",
        "!pip install accelerate==0.23.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face.\n",
        "\n",
        "Fornece uma maneira direta de usar modelos pré-treinados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RfUN_KolV-f",
        "outputId": "f87963d8-b37a-4ad0-b82c-10e719c5490d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "# Instala a última versão da biblioteca\n",
        "# !pip install transformers\n",
        "\n",
        "# A última versão do huggingface apresenta um problema:\n",
        "# UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1`\n",
        "# https://discuss.huggingface.co/t/help-with-llama-2-finetuning-setup/50035\n",
        "# Usar a versão 4.31.0\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.31.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlrWrRP02tuZ"
      },
      "source": [
        "Instala o cliente do huggingface hub para realizar o login."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxtD3Zk14ov",
        "outputId": "ab39705f-64c3-4cc9-e0c4-6c01d2f5a592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub==0.18.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "# 2 - Carregando o LLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFRSYoCArrQ-"
      },
      "source": [
        "## 2.1 - Login no huggingface\n",
        "\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "\n",
        "Insira o token quando solicitado e depois digite Y para adicionar as credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bkqIoNU18UH"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACJuj9wB9kjZ"
      },
      "source": [
        "Se o seu notebook não for público e não desejar incluir o token de acesso toda vez que for executar o notebook preencha o método save_token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRVr7uqp9Ubk"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.hf_api import HfFolder\n",
        "\n",
        "ACCESS_TOKEN  = 'COLOQUE O SEU TOKEN DE ACESSO AQUI'\n",
        "\n",
        "HfFolder.save_token(ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzrrJLw9oQd"
      },
      "source": [
        "Mostrando o usuário conectado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLrSstlxR_kq"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niwUEmYM6kjG"
      },
      "source": [
        "## 2.2 - Nome do modelo de linguagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBOzL86X6kjM"
      },
      "source": [
        "Define o nome do modelo a ser carregado\n",
        "Lista dos modelos:\n",
        "  - https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-13b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-70b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-70b-chat-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zOnSymM6kjM"
      },
      "outputs": [],
      "source": [
        "#nome_modelo = \"meta-llama/Llama-2-7b-hf\"\n",
        "nome_modelo = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "#nome_modelo = \"meta-llama/Llama-2-13b-hf\"\n",
        "# nome_modelo = \"meta-llama/Llama-2-13b-chat-hf\"\n",
        "\n",
        "# Não roda pois exige GPU A100 e mais espaço em disco\n",
        "#nome_modelo = \"meta-llama/Llama-2-70b-hf\"\n",
        "# nome_modelo = \"meta-llama/Llama-2-70b-chat-hf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWcQNSORrYC"
      },
      "source": [
        "## 2.3 - Carrega o tokenizador\n",
        "\n",
        "Carregando o **tokenizador** da comunidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlSM1VufRw5B",
        "outputId": "e43ff0cf-3942-4659-b7c6-44938df43aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o tokenizador meta-llama/Llama-2-7b-chat-hf da comunidade...\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do Tokenizador\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregando o Tokenizador da comunidade\n",
        "print('Carregando o tokenizador ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNMEhN9BHuc"
      },
      "source": [
        "## 2.4 - Carregando o Modelo LLM\n",
        "\n",
        "Carregando o **modelo** da comunidade Huggingface.\n",
        "\n",
        "Parametrização do from_pretrained\n",
        "https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "b39eeb281bb84bbf9574328e1f1762e4",
            "de20eb50bc1b457aa24cbeb71b1c8d8e",
            "dde91073434e4807953bd3a5b29a1dd6",
            "7b39137fc2f649dc96bfdb1619e28ec9",
            "9e9b535f0cc34f348048606224eb7952",
            "b6c836223fc84d4fb56381334beea0c9",
            "86c1e0ae5d214d42aebb7e9836473dc0",
            "b4f65d0206f64282bc763f26dac67156",
            "d2bf4b0767004e71b8a2aaa9789fcb1b",
            "8ac466341d2f4a229d104da0355bf0f3",
            "844d00018c674a9c900b44e32faa8c11"
          ]
        },
        "id": "zH_tnwWJRnQL",
        "outputId": "5cf87b29-b5b0-47ae-bbeb-2032062008ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo meta-llama/Llama-2-7b-chat-hf da comunidade...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b39eeb281bb84bbf9574328e1f1762e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de carregamento do modelo LLM:  0:01:15 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import AutoModelForCausalLM\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Carregando o Modelo da comunidade\n",
        "print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "                                             #torch_dtype=torch.float16, #default\n",
        "                                             trust_remote_code=True,   # Carrega de um repositório confiável\n",
        "                                             load_in_8bit=True,\n",
        "                                             device_map=\"auto\"\n",
        "                                             )\n",
        "\n",
        "# Coloca o modelo e modo avaliação\n",
        "model.eval()\n",
        "\n",
        "print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqp5fuyRWc4",
        "outputId": "ad168b31-ec4c-43a7-fa77-e7e27c0c7d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n"
          ]
        }
      ],
      "source": [
        "print(model.config.max_position_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXgoG2ZvuHFI",
        "outputId": "349db143-175e-4454-f255-ae9159a711f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
            "    \"bnb_4bit_quant_type\": \"fp4\",\n",
            "    \"bnb_4bit_use_double_quant\": false,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": false,\n",
            "    \"load_in_8bit\": true\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 - Cria o pipeline usando Langchain\n",
        "\n",
        "Cria o pipeline com a classe [HuggingFacePipeline](https://api.python.langchain.com/en/latest/llms/langchain.llms.huggingface_pipeline.HuggingFacePipeline.html) do langchain."
      ],
      "metadata": {
        "id": "ZGiVSTl1rwAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passagem direta do pipeline Huggingface.\n",
        "\n",
        "Configura o pipeline do Huggingface usando o modelo e tokenizador previamente carregado e passa para o HuggingFacePipeline do langchain."
      ],
      "metadata": {
        "id": "Q7kqNDonwh49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configura o pipeline do HuggingFace\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    trust_remote_code=True,\n",
        "    max_length=2048,\n",
        "    #top_k=3,\n",
        "    # num_return_sequences=1,\n",
        "    # max_new_tokens = 10 # Limita a quantidade de tokens gerada\n",
        ")\n",
        "\n",
        "# Carrega o pipeline do Langchain\n",
        "# https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
        "model_llm = HuggingFacePipeline(\n",
        "    pipeline=pipe,\n",
        "    model_kwargs={\"temperature\": 0.1})"
      ],
      "metadata": {
        "id": "f2WhTkmAZrNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFReKYmi8bdb",
        "outputId": "eecaf54b-4b65-4c0d-a5ac-eccb479f458f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mHuggingFacePipeline\u001b[0m\n",
            "Params: {'model_id': 'gpt2', 'model_kwargs': {'temperature': 0.1}, 'pipeline_kwargs': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 - Carregando o ML BERT\n",
        "\n",
        "Download do BERT via HuggingFace\n",
        "\n",
        "Os modelos [BGE](https://python.langchain.com/docs/integrations/text_embedding/bge_huggingface) no HuggingFace são os melhores modelos de embeddings de código aberto. O modelo BGE é criado pela Academia de Inteligência Artificial de Pequim(*Beijing Academy of Artificial Intelligence*-BAAI) . BAAI é uma organização privada sem fins lucrativos envolvida em pesquisa e desenvolvimento de IA."
      ],
      "metadata": {
        "id": "4Wpi2LXFZ-Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "#MODELO_BERT = \"bert-large-cased\"\n",
        "#MODELO_BERT = \"bert-base-cased\"\n",
        "MODELO_BERT = \"neuralmind/bert-large-portuguese-cased\"\n",
        "#MODELO_BERT = \"neuralmind/bert-base-portuguese-cased\"\n",
        "\n",
        "# Carrega os embeddings diretamente do HuggingFace\n",
        "model_lm = HuggingFaceBgeEmbeddings(\n",
        "    model_name=MODELO_BERT,\n",
        "    model_kwargs={'device': 'cuda'},\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "\n",
        "print(\"Tempo de carregamento do modelo LM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVRiwo7PZ_VM",
        "outputId": "5c7962b7-dc7d-4ec5-d094-bebe87234d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de carregamento do modelo LM:  0:00:12 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_lm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcyVsy-_9SEr",
        "outputId": "4d761f91-d5dd-4610-eb78-31a9146de93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
            ") model_name='neuralmind/bert-large-portuguese-cased' cache_folder=None model_kwargs={'device': 'cuda'} encode_kwargs={'normalize_embeddings': True} query_instruction='Represent this question for searching relevant passages: '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgiKWHXxafKf"
      },
      "source": [
        "# 3 - Pergunta em texto longo\n",
        "\n",
        "Artigos que auxiliaram a criar o recuperador de texto de perguntas em texto longo.\n",
        "\n",
        "https://heidloff.net/article/retrieval-augmented-generation-chroma-langchain/\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 - Carrega os documentos de PDF"
      ],
      "metadata": {
        "id": "3w7ApoLkx83r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 - Download do PDF"
      ],
      "metadata": {
        "id": "I4Fj8pNPyOR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download do PDF do livro \"As Vítimas Algozes\".\n",
        "\n",
        "Biblioteca: https://www.literaturabrasileira.ufsc.br/documentos/?id=142070\n",
        "\n",
        "PDF: https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116977"
      ],
      "metadata": {
        "id": "wd4GcvfCz7L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "# import subprocess\n",
        "\n",
        "# # As Vítimas Algozes\n",
        "# urlpdf = 'https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116977'\n",
        "\n",
        "# destino = 'arquivo1.pdf'\n",
        "\n",
        "# # Executa o comando wget no prompt\n",
        "# subprocess.call([\"wget\", urlpdf, \"-O\", destino])"
      ],
      "metadata": {
        "id": "WbAPtRSxyuIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 - Carrega do PDF\n",
        "\n"
      ],
      "metadata": {
        "id": "kRx-vabm0Vbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import das bibliotecas\n",
        "# from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "# # Define o diretório\n",
        "# diretorio = '/content'\n",
        "\n",
        "# # Cria o carregar dos documentos do diretório\n",
        "# # Pode ser usado o PyPDFLoader para um arquivo\n",
        "# carregador = PyPDFDirectoryLoader(diretorio)\n",
        "\n",
        "# # Carrega os documentos\n",
        "# documentos = carregador.load()"
      ],
      "metadata": {
        "id": "j18ncV8e0B8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Carrega os documentos da WEB\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed"
      ],
      "metadata": {
        "id": "P5tgQFvgx4UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Download da WEB\n",
        "\n",
        "Download do PDF do livro \"As Vítimas Algozes\".\n",
        "\n",
        "Biblioteca: https://www.literaturabrasileira.ufsc.br/documentos/?id=142070\n",
        "\n",
        "HTML: https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116979"
      ],
      "metadata": {
        "id": "afsQSgK3yiXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116979\"\n",
        "\n",
        "# Cria o carregador da página\n",
        "carregador = WebBaseLoader(url)\n",
        "\n",
        "# Carrega os documentos\n",
        "documentos = carregador.load()"
      ],
      "metadata": {
        "id": "UO97RTfwxUDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exibe parte dos dados carregados"
      ],
      "metadata": {
        "id": "GE12a2SGoFCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de documentos(páginas):\", len(documentos))\n",
        "pagina = 0\n",
        "print(\"Trecho página(\", pagina, \") :\", documentos[pagina].page_content[0:500])\n",
        "print()\n",
        "print(\"Medadados:\", documentos[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQFU9kiPVT5B",
        "outputId": "49b66029-c8eb-4e01-94f2-13179aad2834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de documentos(páginas): 1\n",
            "Trecho página( 0 ) : \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "As vítimas algozes - Joaquim Manuel de Macedo\n",
            "\n",
            "\n",
            "\n",
            "Fonte: Biblioteca Digital de Literatura de Países Lusófonos\n",
            "\n",
            "LITERATURA BRASILEIRA \n",
            "Textos literários em\n",
            "meio eletrônico\n",
            "As\n",
            "Vítimas-Algozes, de Joaquim Manuel de Macedo\n",
            "\n",
            "Edição de base:\n",
            "Biblioteca Nacional – setor de obras digitalizadas\n",
            "ÍNDICE\n",
            "SIMEÃO, O CRIOULO\n",
            "PAI- RAIOL, O FEITICEIRO\n",
            "LUCINDA, A\n",
            "MUCAMA\n",
            "CONCLUSÃO\n",
            "I\n",
            "SIMEÃO, O CRIOULO\n",
            "I\n",
            "No interior e principalmente longe da vila, ou da\n",
            "freguesia e dos povoados há quase sempre uma ven\n",
            "\n",
            "Medadados: {'source': 'https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116979', 'title': 'As vítimas algozes - Joaquim Manuel de Macedo', 'description': 'As vítimas algozes - Joaquim Manuel de Macedo', 'language': 'No language found.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 - Carrega e divide os documentos\n",
        "\n",
        "Carrega o documentos e realiza o divisão do documento em pedaços(chunks) e faz a sobreposição(overlap) para garantir o contexto semântico entre os pedaços.\n",
        "\n",
        "Teste online da chunk(divisão) e overlap(overlap) usando um arquivo texto no link: https://chunkerizer.streamlit.app/"
      ],
      "metadata": {
        "id": "CFY2d-y60scC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Parâmetros\n",
        "chunk_tamanho = 2048\n",
        "chunk_sobreposicao = 750\n",
        "\n",
        "# Configura o divisor\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = chunk_tamanho,\n",
        "    chunk_overlap  = chunk_sobreposicao, # Número de tokens sobrepostos entre chunks(pedaços)\n",
        "    length_function = len, # Usa o comprimento do texto como medida de tamanho\n",
        "    add_start_index = True, #\n",
        ")\n",
        "\n",
        "# Guarda o tempo de início\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Calcula os chunks dos documentos\n",
        "chunks = text_splitter.split_documents(documentos)\n",
        "\n",
        "tempo_final = time.time()\n",
        "\n",
        "print(f\"Carregando e dividindo {len(documentos)} documentos html em {tempo_final - tempo_inicio} segundos!\")\n",
        "print(f\"Quantidade de chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710c7384-73ac-4425-89fc-c8668f0fd50a",
        "id": "SENyOAu30scC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando e dividindo 1 documentos pdfs em 0.05613231658935547 segundos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 - Armazena os chunks\n",
        "\n",
        "Utiliza o Chroma um banco de dados de embeddings de código aberto e leve.\n",
        "\n",
        "https://www.trychroma.com/\n",
        "\n",
        "https://heidloff.net/article/retrieval-augmented-generation-chroma-langchain/"
      ],
      "metadata": {
        "id": "cLSk7vNBWMla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Armazena os chunks usando o Chroma\n",
        "vectorstore = Chroma.from_documents(documents=chunks, embedding=model_lm, persist_directory=\"./bancodedados\", )"
      ],
      "metadata": {
        "id": "rsXZLkeCWPIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epsEHDsGQJAC"
      },
      "source": [
        "## 3.5 - Função de envio de perguntas ao LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import PromptTemplate\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "def avaliarContexto(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Você é um assistente de IA útil e fornece a resposta para a pergunta com base no contexto fornecido.\n",
        "Contexto: {context}\n",
        ">>PERGUNTA<< {question}\n",
        ">>RESPOSTA<<\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  # As variáveis \"context\" e \"question\" não podem ser alteradas\n",
        "  prompt = PromptTemplate(input_variables=[\"context\", \"question\"],\n",
        "                          template=prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain_type_kwargs = {\"prompt\": prompt}\n",
        "  chain = RetrievalQA.from_chain_type(\n",
        "        llm=model_llm,\n",
        "        chain_type=\"stuff\",\n",
        "        #retriever=vectorstore.as_retriever(), # Passa o contexto(livro carregado)\n",
        "        retriever=vectorstore.as_retriever(search_kwargs={'k':1}), # Passa o contexto(livro carregado)\n",
        "        chain_type_kwargs=chain_type_kwargs\n",
        "    )\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.run(texto)\n",
        "\n",
        "  # Esvazia a memória\n",
        "  # del chain\n",
        "  # gc.collect()\n",
        "  # torch.cuda.empty_cache()\n",
        "\n",
        "  return resultado"
      ],
      "metadata": {
        "id": "ToMVt5GkkqEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6 - Algumas perguntas usando o contexto"
      ],
      "metadata": {
        "id": "l_iS635Fftog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guarda o tempo de início de realização das perguntas"
      ],
      "metadata": {
        "id": "GYZeuWBf6AV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()"
      ],
      "metadata": {
        "id": "qxGyZ-El6DK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCeR9lv5_Fxd",
        "outputId": "b173572e-3a35-47c4-9700-a44d4f3492fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O período que ocorre a história do texto é o Segundo Império, pois é mencionado o Rio de Janeiro e a cidade de São Paul\n",
            "o, que eram as capitais do Brasil na época. Além disso, é mencionado o império, o que indica que o texto ocorre durante \n",
            "o Segundo Império, que durou de 1852 a 1870.\n"
          ]
        }
      ],
      "source": [
        "texto = \"Qual o período que ocorre a história do texto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto em qual período que ocorre os fatos?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBbhBnY3ul45",
        "outputId": "bb04fb5d-2119-4113-ff6a-d57f1eff5450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O contexto é do século XIX, no Brasil, no início do século, cerca de 1820.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Quem são os principais personagens do contexto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcJwBtkRfvwy",
        "outputId": "e8205bd9-36f4-4cfe-ba9b-6692e8033437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os principais personagens do contexto são:\n",
            "\n",
            "1. Deus: é o criador do universo e dos seres humanos, e é considerado o sen\n",
            "hor e o dono de todos.\n",
            "2. Homens: são os seres humanos, que são considerados como escravos de Deus e de seus opressores.\n",
            "\n",
            "3. Escravos: são os seres humanos que são considerados como miseráveis e degradados pela condição violentada em que viv\n",
            "em.\n",
            "4. Opressores: são os seres humanos que opressam e exploram os escravos, e são considerados como responsáveis pela e\n",
            "scravidão.\n",
            "5. Esposas e filhas: são as mulheres que são relacionadas com os homens e os escravos, e são consideradas com\n",
            "o sendo vulneráveis ao contacto e à influência dos escravos.\n",
            "\n",
            "Esses são os principais personagens do contexto, e eles sã\n",
            "o relacionados entre si de maneira complexa e interdependente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto quem são os principais personagens da história?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncDCuO8InX4Q",
        "outputId": "83d79512-5786-41fd-96d3-4bf6d42aa51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os principais personagens da história são os escravos, que são descritos como \"miseráveis degradados pela condição viol\n",
            "entada\", \"engolfados nos vícios mais torpes\", \"materializados\", \"corruptos\", \"apodrecidos na escravidão\" e \"pestíferos p\n",
            "elo viver no pantanal da peste\". Eles são vistos como sendo \"com vossas esposas\", \"com vossas filhas\", e como tendo um i\n",
            "mpacto negativo na sociedade escravagista.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Em que pais e cidade ocorreram os fatos?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14uToJBegMTl",
        "outputId": "5d318045-abce-4c66-8485-7b26f6bb30fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os fatos ocorreram no Brasil, no século XIX, durante a época da escravidão. A obra \"Bani a Escravidão!\" é de José de Al\n",
            "encar, um escritor brasileiro do século XIX, e foi publicada em 1870. A obra é uma crítica à escravidão e aos opressores\n",
            " que a praticavam no Brasil.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Em que pais e cidade ocorre os fatos do contexto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "6rCzERypucnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128e1cd0-7b65-4a4e-f57a-4d48c49a21b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O contexto ocorre em uma cidade do Brasil, não especificada, na época do Império Braziliense.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Quais palavras possuem relação com escravidão?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hoD9rKpgVwv",
        "outputId": "606eb0b5-89c7-4058-a2ce-d2f35912aba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras que possuem relação com escravidão são:\n",
            "\n",
            "* Deus\n",
            "* senhores\n",
            "* donos\n",
            "* escravos\n",
            "* peste\n",
            "* tão vis\n",
            "* tão perig\n",
            "osos\n",
            "* desmoralizando\n",
            "* envenenando\n",
            "* desonrando\n",
            "* empestando\n",
            "* assassinando\n",
            "* Bani a escravidão\n",
            "\n",
            "Essas palavras são usa\n",
            "das no contexto da obra \"O Escravo Antes do Café\" de José de Alencar, onde o autor critica a escravidão e a opressão que\n",
            " os escravos sofrem nas mãos dos senhores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto que palavras possuem relação com escravidão?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Tv5t_9nFTG",
        "outputId": "a1814422-b096-4dfb-fd52-9fcaef4fcd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras que possuem relação com a escravidão são:\n",
            "\n",
            "1. Senhores: Refere-se aos proprietários de escravos, que tinham\n",
            " o direito de possuir e explorar trabalhadores escravos.\n",
            "2. Escravos: Refere-se aos trabalhadores que eram propriedade d\n",
            "e outros e eram obrigados a realizar trabalhos forçados.\n",
            "3. Donos: Refere-se aos proprietários de escravos, que tinham o\n",
            " direito de possuir e explorar trabalhadores escravos.\n",
            "4. Árbitros: Refere-se aos indivíduos que tinham o poder de julga\n",
            "r e resolver conflitos entre os escravos e seus proprietários.\n",
            "5. Peste: Refere-se à epidemia de doenças que afetava os \n",
            "escravos e seus proprietários, tornando-os mais vulneráveis à escravidão.\n",
            "6. Tão vis, tão perigosos: Refere-se à ideia d\n",
            "e que os escravos eram vistos como uma ameaça para a sociedade, e que sua presença era perigosa para os proprietários.\n",
            "7\n",
            ". Empestando, assassinando: Refere-se à ideia de que a escravidão era uma doença que afetava a sociedade como um todo, e\n",
            " que era capaz de matar a sociedade se não fosse combater.\n",
            "8. Desmoralizando, envenenando: Refere-se à ideia de que a es\n",
            "cravidão era uma doença que afetava a moral e a ética da sociedade, e que era capaz de corromper a sociedade se não foss\n",
            "e combater.\n",
            "\n",
            "Essas palavras são usadas para expressar a ideia de que a escravidão era uma doença que afetava a sociedade\n",
            " como um todo, e que era capaz de matar a sociedade se não fosse combater.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto que palavras possuem relação semântica com escravidão?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "F-Rfy2vjlkVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0983ee11-38d8-41fd-e2d8-baf64a33ccd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras que possuem relação semântica com escravidão são:\n",
            "\n",
            "1. Opressores: Refere-se a um indivíduo ou grupo que exe\n",
            "rce o poder de maneira cruenta ou oppressiva sobre outros.\n",
            "2. Desonrando: Significa desacreditar ou desvirginar algo ou \n",
            "alguém, relacionando-se à ideia de que a escravidão é uma forma de desonorar os escravos e sua condição humana.\n",
            "3. Empes\n",
            "tando: Refere-se a uma substância ou ação que cause um cheiro desagradável ou nocivo, relacionando-se à ideia de que a e\n",
            "scravidão é uma forma de \"empestar\" os escravos e a sociedade como um todo.\n",
            "4. Assassinando: Significa matar ou causar a\n",
            " morte de alguém, relacionando-se à ideia de que a escravidão é uma forma de assassinato cultural e social dos escravos.\n",
            "\n",
            "5. Desmoralizando: Refere-se a uma ação ou situação que cause a perda da moral ou da integridade de alguém, relacionand\n",
            "o-se à ideia de que a escravidão é uma forma de desmoralizar os escravos e sua condição humana.\n",
            "6. Envenenando: Signific\n",
            "a causar danos ou problemas a alguém ou algo, relacionando-se à ideia de que a escravidão é uma forma de envenenar os es\n",
            "cravos e a sociedade como um todo.\n",
            "7. Bani: É um termo que significa \"banir\" ou \"proibir\", relacionando-se à ideia de qu\n",
            "e a escravidão deve ser banida ou proibida da sociedade.\n",
            "\n",
            "Essas palavras possuem relação semântica com escravidão pois c\n",
            "ompartilham temas de oppressão, desonoramento, desvantagem, danos e proibição, que são fundamentais para a compreensão d\n",
            "a escravidão como um sistema oppressivo e injusto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto que palavras estão relacionadas a escravidão mas deixa isto implicito?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "f8mj1-zTg-H4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2016ef-c1fc-41c9-caf1-ac739dcd62ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sim, é possível que as palavras relacionadas a escravidão estejam implicitamente presentes na obra, mesmo que não estej\n",
            "am explicitamente mencionadas. A escravidão era uma realidade da sociedade brasileira no tempo da obra e pode ter sido r\n",
            "eferenciada de forma implícita através de imagens, metáforas ou outros elementos literários. Por exemplo, a ideia de \"mi\n",
            "seráveis degradados pela condição violentada\" pode ser uma referência à escravidão, mesmo que não esteja explicitamente \n",
            "mencionada. Além disso, a obra pode conter críticas à escravidão de forma implícita através de personagens ou situações \n",
            "que representam a opposição à escravidão.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Texto do trabalho do **Leandro**"
      ],
      "metadata": {
        "id": "DvgszcoyBc0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando a palavra \\\"negro\\\" com alvo, identifique outras palavras no contexto que são semanticamente similares.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "Iq9QgnkNitc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92078b1f-3ecb-4bea-b2c6-99c205efe498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ao considerar a palavra \"negro\" com alvo, outras palavras semanticamente similares que podem ser identificadas no conte\n",
            "xto são:\n",
            "\n",
            "* Preto\n",
            "* Escravo\n",
            "* Africano\n",
            "* Mulato\n",
            "* Moreno\n",
            "\n",
            "Essas palavras compartilham a mesma conotação negativa e de op\n",
            "ressão que a palavra \"negro\" com alvo, e são frequentemente usadas de forma intercambiável para referir pessoas de cor e\n",
            "scura. No entanto, é importante notar que essas palavras não são sinônimas exatas, e cada uma tem um contexto e uma hist\n",
            "ória específicos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \" Na sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ lista as palavras possuem ligação com a palavra \\'negro\\'\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "2m-pBVlIiifv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e282960-235d-42b4-d97d-28f02185c984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Na sentença 'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da v\n",
            "ingança.' as palavras 'escravo', 'negro' e'vergonha' estão relacionadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \" Na sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ lista as palavras possuem ligação com a palavra alvo \\'negro\\' considerando o contexto.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "b1h37tw8jrOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cba50a9-3013-42e1-9db8-7ec5161e5c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Na sentença 'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da v\n",
            "ingança.' as palavras 'negro' e 'escravo' estão relacionadas, pois o escravo é descrito como 'negro'. No contexto da his\n",
            "tória, o termo 'negro' é usado para descrever os escravos, que são pessoas de cor preta. Portanto, a resposta à pergunta\n",
            " é que as palavras 'negro' e 'escravo' estão relacionadas no sentido de que o escravo é descrito como um 'negro'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Usando leitura distante realize a analise da sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ para encontrar e listar as palavras possuem ligação com a palavra alvo \\'negro\\'.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "WFS-f5Q0j8Si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaf4bdd-9c6d-4782-99b0-3836a85b14b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A sentença 'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vin\n",
            "gança.' contém as seguintes palavras que possuem ligação com a palavra alvo 'negro':\n",
            "\n",
            "1. falta\n",
            "2. escravidão\n",
            "3. negro\n",
            "4.\n",
            " rancor\n",
            "5. vingança\n",
            "\n",
            "Essas palavras possuem uma conexão semântica com a palavra 'negro', pois elas estão relacionadas ao\n",
            " tema da escravidão e ao status social dos negros na época.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto use leitura distante para realizar a analise da sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ para encontrar e listar as palavras possuem ligação com a palavra alvo \\'negro\\'.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "gZ4hwllSmR35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07eb4f7b-be2d-4498-f24f-aa63535c8aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ao considerar a sentença 'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o\n",
            " desejo da vingança.' no contexto da história, as palavras que possuem ligação com a palavra alvo 'negro' são:\n",
            "\n",
            "1. escra\n",
            "vidão\n",
            "2. escravo\n",
            "3. negro\n",
            "4. pundonor\n",
            "5. vergonha\n",
            "6. rancor\n",
            "7. vingança\n",
            "\n",
            "Essas palavras possuem uma conexão semântica co\n",
            "m a palavra alvo 'negro', pois são usadas para descrever a condição social e a situação de opressão dos escravos, que er\n",
            "am majoritariamente negros. Ao considerar a sentença no contexto da história, é importante lembrar que a escravidão era \n",
            "uma prática comum no Brasil colonial, e que os escravos eram majoritariamente negros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Usando leitura distante realize a analise da sentença: \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ e liste as palavras possuem relação semântica com a palavra alvo \\'negro\\'.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "XDEpYSHhkzcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7dc4a9-caaf-481b-ae47-1b080f574e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras que possuem relação semântica com a palavra alvo 'negro' na sentença analisada são:\n",
            "\n",
            "* rancor\n",
            "* desejo\n",
            "* vi\n",
            "ngança\n",
            "* escravidão\n",
            "* pundonor\n",
            "* vergonha\n",
            "\n",
            "Essas palavras compartilham a mesma semântica de 'negro' como 'escravo','mise\n",
            "rável', 'degradado', 'violentado', 'pestífero', 'torpe', 'perigoso', 'obrigado', 'fatal', 'envenenando', 'desonrando', '\n",
            "empestando', 'assassinando'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tempo final de execução das perguntas"
      ],
      "metadata": {
        "id": "1JZDLa5p52S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tempo de execução das perguntas:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvTh9EVI548_",
        "outputId": "14ad5d27-febd-4f0f-ff1d-44106c098e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução das perguntas:  0:12:03 (h:mm:ss)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b39eeb281bb84bbf9574328e1f1762e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de20eb50bc1b457aa24cbeb71b1c8d8e",
              "IPY_MODEL_dde91073434e4807953bd3a5b29a1dd6",
              "IPY_MODEL_7b39137fc2f649dc96bfdb1619e28ec9"
            ],
            "layout": "IPY_MODEL_9e9b535f0cc34f348048606224eb7952"
          }
        },
        "de20eb50bc1b457aa24cbeb71b1c8d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c836223fc84d4fb56381334beea0c9",
            "placeholder": "​",
            "style": "IPY_MODEL_86c1e0ae5d214d42aebb7e9836473dc0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dde91073434e4807953bd3a5b29a1dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f65d0206f64282bc763f26dac67156",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2bf4b0767004e71b8a2aaa9789fcb1b",
            "value": 2
          }
        },
        "7b39137fc2f649dc96bfdb1619e28ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac466341d2f4a229d104da0355bf0f3",
            "placeholder": "​",
            "style": "IPY_MODEL_844d00018c674a9c900b44e32faa8c11",
            "value": " 2/2 [01:00&lt;00:00, 27.64s/it]"
          }
        },
        "9e9b535f0cc34f348048606224eb7952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c836223fc84d4fb56381334beea0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c1e0ae5d214d42aebb7e9836473dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4f65d0206f64282bc763f26dac67156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bf4b0767004e71b8a2aaa9789fcb1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ac466341d2f4a229d104da0355bf0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844d00018c674a9c900b44e32faa8c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}