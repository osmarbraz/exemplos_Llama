{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_Llama/blob/main/ExemploRespondendoPerguntaTextoLongo_Llama2_Langchain_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Respondendo Perguntas sobre Textos Longos usando Llama v2.0, Longchain, Chroma e Transformers by HuggingFace\n",
        "\n",
        "**Toda a execução ocorre no Google Colaboratory.**\n",
        "\n",
        "Pré-requisitos:\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "- Configurar o notebook para usar GPU- Acesse o menu 'Ambiente de Execução -> Alterar o tipo do ambiente de execução -> Acelerador de hardware -> T4 GPU\n",
        "\n",
        "\n",
        "**Referências**\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed\n",
        "\n",
        "**Lista dos modelos:**\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "## Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "outputs": [],
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "outputs": [],
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmhxcvIfbG2"
      },
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603LYIYKBmq5"
      },
      "source": [
        "Função auxiliar para formatar o tempo como `hh: mm: ss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guy6B4whsZFR"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas.\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def formataTempo(tempo):\n",
        "    \"\"\"\n",
        "      Pega a tempo em segundos e retorna uma string hh:mm:ss\n",
        "    \"\"\"\n",
        "    # Arredonda para o segundo mais próximo.\n",
        "    tempo_arredondado = int(round((tempo)))\n",
        "\n",
        "    # Formata como hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=tempo_arredondado))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprime linhas menores."
      ],
      "metadata": {
        "id": "V1vu-ch8yT5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_linhas_menores(texto, tamanho=120):\n",
        "  for i in range(0, len(texto), tamanho):\n",
        "    print(texto[i:i+tamanho])"
      ],
      "metadata": {
        "id": "8BKQZtF9yUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 1 - Instalação das bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteca para manipular pdf\n",
        "\n",
        "https://pypi.org/project/pypdf/"
      ],
      "metadata": {
        "id": "akFHj1OT0eCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf==3.16.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mdrRBD_0gAL",
        "outputId": "01a661c1-215e-4ce0-b244-e585687495ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf==3.16.4 in /usr/local/lib/python3.10/dist-packages (3.16.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliota de dependência para manipular os embeddings pelo Langchain.\n",
        "\n",
        "https://pypi.org/project/sentence-transformers/"
      ],
      "metadata": {
        "id": "IHKbYosXal6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers==2.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQYsLbh1aoEe",
        "outputId": "9d110508-0738-49be-be21-e36c57547a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers==2.2.2) (12.3.52)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers==2.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\n",
            "Collecting torch>=1.6.0 (from sentence_transformers==2.2.2)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers==2.2.2) (9.4.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch>=1.6.0->sentence_transformers==2.2.2)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2) (0.41.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers==2.2.2) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers==2.2.2) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0\n",
            "    Uninstalling torch-2.1.0:\n",
            "      Successfully uninstalled torch-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.22.post7 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteca que persiste os embeddings e realiza busca semântica.\n",
        "\n",
        "https://pypi.org/project/chromadb/"
      ],
      "metadata": {
        "id": "xX6UfQIXbZGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.4.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQKufOHtbbAc",
        "outputId": "e5ac83d6-cd69-44dc-f305-bd64343a4f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb==0.4.15 in /usr/local/lib/python3.10/dist-packages (0.4.15)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.10.13)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.104.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.23.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (4.8.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.16.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.13.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (6.1.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.59.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (4.0.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (28.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (8.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.15) (1.23.5)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.4.15) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.4.15) (0.27.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (6.0.1)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.6.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (3.2.2)\n",
            "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.26.18)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (6.8.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.61.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.20.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.20.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.41b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.15) (0.41b0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.15) (1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.15) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.15) (3.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.4.15) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb==0.4.15) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb==0.4.15) (1.1.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.15) (3.17.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.15) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteca para realizar a divisão por token."
      ],
      "metadata": {
        "id": "YIz5_pcBneGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken==0.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO0tpmblneRf",
        "outputId": "e7a051be-942d-4f17-bcab-f35f47b8f496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken==0.5.1 in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibioteca LangChain é um framework de código aberto para o desenvolvimento de aplicações usando modelos de linguagem grandes.\n",
        "\n",
        "https://pypi.org/project/langchain/"
      ],
      "metadata": {
        "id": "PGrlTKgSLdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.0.323"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppVeArJcLdVb",
        "outputId": "28c3ade6-a2ec-4f7c-9e33-d84fa7686b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.0.323 in /usr/local/lib/python3.10/dist-packages (0.0.323)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (0.0.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.323) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.323) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.323) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.323) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.323) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.323) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.323) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.323) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.323) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.323) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.323) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.323) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.323) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.323) (4.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.323) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.323) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.323) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.323) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.323) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependências do xformers\n",
        "\n",
        "https://pypi.org/project/lmdb/"
      ],
      "metadata": {
        "id": "upho_jty-L2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb==1.4.1\n",
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 torchtext==0.15.2+cpu torchdata==0.6.1 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "VgO9dhZX66Va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9109bccf-be35-4fcb-e63b-4a2572bf7e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lmdb==1.4.1 in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "Requirement already satisfied: torchvision==0.15.2+cu118 in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: torchtext==0.15.2+cpu in /usr/local/lib/python3.10/dist-packages (0.15.2+cpu)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2+cpu) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1) (1.26.18)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cu118) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.22.post7 requires torch==2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permite maior velocidade e menor consumo de memória nos transformers.\n",
        "\n",
        "https://pypi.org/project/xformers/"
      ],
      "metadata": {
        "id": "bDqzuP1kqPZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers==0.0.22.post7"
      ],
      "metadata": {
        "id": "Evr5Vtp0qWE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76e1812-02b8-4a78-c485-7bda683fc81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers==0.0.22.post7 in /usr/local/lib/python3.10/dist-packages (0.0.22.post7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.22.post7) (1.23.5)\n",
            "Collecting torch==2.1.0 (from xformers==0.0.22.post7)\n",
            "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->xformers==0.0.22.post7)\n",
            "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers==0.0.22.post7) (12.3.52)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers==0.0.22.post7) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers==0.0.22.post7) (1.3.0)\n",
            "Installing collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.15.2+cpu requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0 triton-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0jVfo3QM3h"
      },
      "source": [
        "O bitsandbytes é um wrapper leve em torno de funções personalizadas CUDA, em particular otimizadores de 8 bits, multiplicação de matrizes (LLM.int8()) e funções de quantização. É uma dependência do accelerate.\n",
        "\n",
        "https://pypi.org/project/bitsandbytes/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12GE2W3fQM_n",
        "outputId": "9b4c6699-75cc-4f83-dc52-247b79a00f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes==0.41.1 in /usr/local/lib/python3.10/dist-packages (0.41.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes==0.41.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wU6vuyAuPd"
      },
      "source": [
        "Accelerate é uma biblioteca que permite que o mesmo código PyTorch seja executado em qualquer configuração distribuída adicionando apenas quatro linhas de código. Otimiza as operações do PyTorch, especialmente na GPU.\n",
        "\n",
        "https://pypi.org/project/accelerate/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTMID1rZAvx7",
        "outputId": "a218d6d1-7117-4ac4-ddb0-b8c1bee40b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==0.24.0 in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.24.0) (12.3.52)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.24.0) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.24.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.24.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.24.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate==0.24.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face.\n",
        "\n",
        "Fornece uma maneira direta de usar modelos pré-treinados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RfUN_KolV-f",
        "outputId": "8ef7d260-9ab7-44b8-eb90-d57d44d85232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "# Instala a última versão da biblioteca\n",
        "# !pip install transformers\n",
        "\n",
        "# A última versão do huggingface apresenta um problema:\n",
        "# UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1`\n",
        "# https://discuss.huggingface.co/t/help-with-llama-2-finetuning-setup/50035\n",
        "# Usar a versão 4.31.0\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.31.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlrWrRP02tuZ"
      },
      "source": [
        "Instala o cliente do huggingface hub para realizar o login."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxtD3Zk14ov",
        "outputId": "3f59bd00-40aa-4d5d-c35a-1a53c7ddd4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.18.0) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.18.0) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub==0.18.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "# 2 - Carregando o LLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFRSYoCArrQ-"
      },
      "source": [
        "## 2.1 - Login no huggingface\n",
        "\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "\n",
        "Insira o token quando solicitado e depois digite Y para adicionar as credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bkqIoNU18UH"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACJuj9wB9kjZ"
      },
      "source": [
        "Se o seu notebook não for público e não desejar incluir o token de acesso toda vez que for executar o notebook preencha o método save_token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRVr7uqp9Ubk"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.hf_api import HfFolder\n",
        "\n",
        "ACCESS_TOKEN  = 'COLOQUE O TOKEN DE ACESSO AQUI'\n",
        "\n",
        "HfFolder.save_token(ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzrrJLw9oQd"
      },
      "source": [
        "Mostrando o usuário conectado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLrSstlxR_kq"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niwUEmYM6kjG"
      },
      "source": [
        "## 2.2 - Nome do LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBOzL86X6kjM"
      },
      "source": [
        "Define o nome do modelo a ser carregado\n",
        "Lista dos modelos:\n",
        "  - https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-13b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-70b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-70b-chat-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zOnSymM6kjM"
      },
      "outputs": [],
      "source": [
        "#nome_modelo = \"meta-llama/Llama-2-7b-hf\"\n",
        "nome_modelo = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "#nome_modelo = \"meta-llama/Llama-2-13b-hf\"\n",
        "#nome_modelo = \"meta-llama/Llama-2-13b-chat-hf\"\n",
        "\n",
        "# Não roda pois exige GPU A100 e mais espaço em disco\n",
        "#nome_modelo = \"meta-llama/Llama-2-70b-hf\"\n",
        "# nome_modelo = \"meta-llama/Llama-2-70b-chat-hf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWcQNSORrYC"
      },
      "source": [
        "## 2.3 - Carrega o tokenizador do LLM\n",
        "\n",
        "Carregando o **tokenizador** da comunidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlSM1VufRw5B",
        "outputId": "1f762967-76b9-4443-dc9a-1da78915967d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o tokenizador meta-llama/Llama-2-7b-chat-hf da comunidade...\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do Tokenizador\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregando o Tokenizador da comunidade\n",
        "print('Carregando o tokenizador ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNMEhN9BHuc"
      },
      "source": [
        "## 2.4 - Carregando o Modelo LLM\n",
        "\n",
        "Carregando o **modelo** da comunidade Huggingface.\n",
        "\n",
        "Parametrização do from_pretrained\n",
        "https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "bced085a22aa42ed92dece59832662a6",
            "debe8121812642c486fe8f2ecb46d3ba",
            "838fa92387cc4038aa55fb83536e5e40",
            "ce0a3273d95748399c76a2934f14ec6c",
            "3a02e9e2b88b4cfab151d04531d4db7b",
            "fc4e683aba794fc1aec7216f13d75efa",
            "835c6b53f2d848c5ac49d01f81dc8bba",
            "dc8dc50783ce48b0958dcb96ac319f8a",
            "9e08f3141c6d4ce6adfd3d7f166bf370",
            "f9996855a7fe487fb8c6d011b5aa022d",
            "abe6629d42ac40fcab72c22aaf1d2860"
          ]
        },
        "id": "zH_tnwWJRnQL",
        "outputId": "7d4fa106-2e5f-4278-e436-6bd42b90e506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo meta-llama/Llama-2-7b-chat-hf da comunidade...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bced085a22aa42ed92dece59832662a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de carregamento do modelo LLM:  0:01:16 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import AutoModelForCausalLM\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Carregando o Modelo da comunidade\n",
        "print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "                                             #torch_dtype=torch.float16, #default\n",
        "                                             trust_remote_code=True,   # Carrega de um repositório confiável\n",
        "                                             load_in_8bit=True,\n",
        "                                             device_map=\"auto\"\n",
        "                                             )\n",
        "\n",
        "# Coloca o modelo e modo avaliação\n",
        "model.eval()\n",
        "\n",
        "print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqp5fuyRWc4",
        "outputId": "00aa1ea9-c9a6-4748-bc80-c36351a8d1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n"
          ]
        }
      ],
      "source": [
        "print(model.config.max_position_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXgoG2ZvuHFI",
        "outputId": "a8833692-2732-4d5e-96e2-18cb2037340b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
            "    \"bnb_4bit_quant_type\": \"fp4\",\n",
            "    \"bnb_4bit_use_double_quant\": false,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": false,\n",
            "    \"load_in_8bit\": true\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 - Cria o pipeline usando Langchain\n",
        "\n",
        "Cria o pipeline com a classe [HuggingFacePipeline](https://api.python.langchain.com/en/latest/llms/langchain.llms.huggingface_pipeline.HuggingFacePipeline.html) do langchain."
      ],
      "metadata": {
        "id": "ZGiVSTl1rwAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passagem direta do pipeline Huggingface.\n",
        "\n",
        "Configura o pipeline do Huggingface usando o modelo e tokenizador previamente carregado e passa para o HuggingFacePipeline do langchain."
      ],
      "metadata": {
        "id": "Q7kqNDonwh49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configura o pipeline do HuggingFace\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    trust_remote_code=True,\n",
        "    max_length=2048,\n",
        "    #top_k=3,\n",
        "    # num_return_sequences=1,\n",
        "    # max_new_tokens = 10 # Limita a quantidade de tokens gerada\n",
        ")\n",
        "\n",
        "# Carrega o pipeline do Langchain\n",
        "# https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
        "model_llm = HuggingFacePipeline(\n",
        "    pipeline=pipe,\n",
        "    model_kwargs={\"temperature\": 0.1})"
      ],
      "metadata": {
        "id": "f2WhTkmAZrNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFReKYmi8bdb",
        "outputId": "1cc147f0-abfd-49b9-efb5-970cb5dbf121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mHuggingFacePipeline\u001b[0m\n",
            "Params: {'model_id': 'gpt2', 'model_kwargs': {'temperature': 0.1}, 'pipeline_kwargs': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 - Nome do LM BERT"
      ],
      "metadata": {
        "id": "VBgsgE4_ik7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#nome_modelo_bert = \"bert-large-cased\"\n",
        "#nome_modelo_bert = \"bert-base-cased\"\n",
        "nome_modelo_bert = \"neuralmind/bert-large-portuguese-cased\"\n",
        "#nome_modelo_bert = \"neuralmind/bert-base-portuguese-cased\""
      ],
      "metadata": {
        "id": "JLU3MXhBipLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 - Carregando o LM BERT\n",
        "\n",
        "A classe HuggingFaceBgeEmbeddings realiza o download do BERT via HuggingFace.\n",
        "\n",
        "Os modelos [BGE](https://python.langchain.com/docs/integrations/text_embedding/bge_huggingface) no HuggingFace são os melhores modelos de embeddings de código aberto. O modelo BGE é criado pela Academia de Inteligência Artificial de Pequim(*Beijing Academy of Artificial Intelligence*-BAAI) . BAAI é uma organização privada sem fins lucrativos envolvida em pesquisa e desenvolvimento de IA."
      ],
      "metadata": {
        "id": "4Wpi2LXFZ-Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Carrega os embeddings diretamente do HuggingFace\n",
        "model_lm = HuggingFaceBgeEmbeddings(\n",
        "    model_name=nome_modelo_bert,\n",
        "    model_kwargs={'device': 'cuda'},\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "\n",
        "print(\"Tempo de carregamento do modelo LM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVRiwo7PZ_VM",
        "outputId": "68bef8cc-81e1-4870-e608-6bbc7b49cb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de carregamento do modelo LM:  0:00:14 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_lm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcyVsy-_9SEr",
        "outputId": "7a9e22a3-df2f-4a98-9582-4187e988c4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
            ") model_name='neuralmind/bert-large-portuguese-cased' cache_folder=None model_kwargs={'device': 'cuda'} encode_kwargs={'normalize_embeddings': True} query_instruction='Represent this question for searching relevant passages: '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o tokenizador do bert"
      ],
      "metadata": {
        "id": "j_ZIFsJdxrA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas do Tokenizador\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregando o Tokenizador da comunidade\n",
        "print('Carregando o tokenizador ' + nome_modelo_bert + ' da comunidade...')\n",
        "\n",
        "tokenizer_bert = AutoTokenizer.from_pretrained(nome_modelo_bert)"
      ],
      "metadata": {
        "id": "3myR-b5OvTIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7975dc7d-1257-453c-f111-d182bed5ebd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o tokenizador neuralmind/bert-large-portuguese-cased da comunidade...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgiKWHXxafKf"
      },
      "source": [
        "# 3 - Pergunta em texto longo\n",
        "\n",
        "Artigos que auxiliaram a criar o recuperador de texto de perguntas em texto longo.\n",
        "\n",
        "https://heidloff.net/article/retrieval-augmented-generation-chroma-langchain/\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 - Carrega os Documentos\n",
        "\n",
        "Carrega de PDF ou HTML.\n",
        "\n",
        "Escolha uma das formas de carregar os dados.\n",
        "\n",
        "Existem outros formas de carregamento.\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/"
      ],
      "metadata": {
        "id": "6unWJreOX_fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 - Carrega os documentos de PDF\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf"
      ],
      "metadata": {
        "id": "3w7ApoLkx83r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Download do PDF\n"
      ],
      "metadata": {
        "id": "I4Fj8pNPyOR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download do PDF do livro \"As Vítimas Algozes\".\n",
        "\n",
        "PDF: https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116977\n",
        "\n",
        "\n",
        "Biblioteca: https://www.literaturabrasileira.ufsc.br/documentos/?id=142070\n"
      ],
      "metadata": {
        "id": "wd4GcvfCz7L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "# import subprocess\n",
        "\n",
        "# # As Vítimas Algozes\n",
        "# urlpdf = 'https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116977'\n",
        "\n",
        "# destino = 'arquivo1.pdf'\n",
        "\n",
        "# # Executa o comando wget no prompt\n",
        "# subprocess.call([\"wget\", urlpdf, \"-O\", destino])"
      ],
      "metadata": {
        "id": "WbAPtRSxyuIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carrega o PDF\n",
        "\n"
      ],
      "metadata": {
        "id": "kRx-vabm0Vbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import das bibliotecas\n",
        "# from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "# # Define o diretório\n",
        "# diretorio = '/content'\n",
        "\n",
        "# # Cria o carregar dos documentos do diretório\n",
        "# # Pode ser usado o PyPDFLoader para um arquivo\n",
        "# carregador = PyPDFDirectoryLoader(diretorio)\n",
        "\n",
        "# # Carrega os documentos\n",
        "# documentos = carregador.load()"
      ],
      "metadata": {
        "id": "j18ncV8e0B8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 - Carrega os documentos da WEB\n",
        "\n",
        "https://python.langchain.com/docs/integrations/document_loaders/web_base\n",
        "\n",
        "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed"
      ],
      "metadata": {
        "id": "P5tgQFvgx4UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carrega o HTML\n",
        "\n",
        "Carrega o HTML do livro \"As Vítimas Algozes\".\n",
        "\n",
        "HTML: https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116979\n",
        "\n",
        "Biblioteca: https://www.literaturabrasileira.ufsc.br/documentos/?id=142070\n",
        "\n"
      ],
      "metadata": {
        "id": "afsQSgK3yiXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "urlhtml = \"https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116979\"\n",
        "\n",
        "# Cria o carregador da página\n",
        "carregador = WebBaseLoader(urlhtml)\n",
        "\n",
        "# Carrega os documentos\n",
        "documentos = carregador.load()"
      ],
      "metadata": {
        "id": "UO97RTfwxUDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exibe parte dos dados carregados do PDF ou HTML."
      ],
      "metadata": {
        "id": "GE12a2SGoFCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de documentos(páginas):\", len(documentos))\n",
        "pagina = 0\n",
        "print(\"Trecho página(\", pagina, \") :\", documentos[pagina].page_content[0:500])\n",
        "print()\n",
        "print(\"Medadados:\", documentos[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQFU9kiPVT5B",
        "outputId": "29b0a71c-6ca3-443f-da9b-86fd25aca9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de documentos(páginas): 1\n",
            "Trecho página( 0 ) : \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "As vítimas algozes - Joaquim Manuel de Macedo\n",
            "\n",
            "\n",
            "\n",
            "Fonte: Biblioteca Digital de Literatura de Países Lusófonos\n",
            "\n",
            "LITERATURA BRASILEIRA \n",
            "Textos literários em\n",
            "meio eletrônico\n",
            "As\n",
            "Vítimas-Algozes, de Joaquim Manuel de Macedo\n",
            "\n",
            "Edição de base:\n",
            "Biblioteca Nacional – setor de obras digitalizadas\n",
            "ÍNDICE\n",
            "SIMEÃO, O CRIOULO\n",
            "PAI- RAIOL, O FEITICEIRO\n",
            "LUCINDA, A\n",
            "MUCAMA\n",
            "CONCLUSÃO\n",
            "I\n",
            "SIMEÃO, O CRIOULO\n",
            "I\n",
            "No interior e principalmente longe da vila, ou da\n",
            "freguesia e dos povoados há quase sempre uma ven\n",
            "\n",
            "Medadados: {'source': 'https://www.literaturabrasileira.ufsc.br/documentos/?action=download&id=116979', 'title': 'As vítimas algozes - Joaquim Manuel de Macedo', 'description': 'As vítimas algozes - Joaquim Manuel de Macedo', 'language': 'No language found.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Divide e sobrepõe os documentos em chuks\n",
        "\n",
        "Carrega o documentos e realiza o divisão do documento em pedaços(chunks) e faz a sobreposição(overlap) para garantir o contexto semântico entre os pedaços.\n",
        "\n",
        "Teste online da chunk(divisão) e overlap(overlap) usando um arquivo texto no link: https://chunkerizer.streamlit.app/"
      ],
      "metadata": {
        "id": "CFY2d-y60scC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Parâmetros\n",
        "chunk_tamanho = 500\n",
        "chunk_sobreposicao = 100\n",
        "\n",
        "# Configura o divisor\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = chunk_tamanho,\n",
        "    chunk_overlap  = chunk_sobreposicao, # Número de tokens sobrepostos entre chunks(pedaços)\n",
        "    #length_function = len, # Usa o comprimento dos caracteres do texto como medida de tamanho\n",
        "    length_function = lambda x: len(tokenizer_bert.tokenize(x)), # Usa a quantidade de tokens gerados pelo tokenizador do BERT como medida de tamanho\n",
        "    add_start_index = True, #\n",
        ")\n",
        "\n",
        "# Guarda o tempo de início\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Calcula os chunks dos documentos\n",
        "chunks = text_splitter.split_documents(documentos)\n",
        "\n",
        "tempo_final = time.time()\n",
        "\n",
        "print(f\"Carregando e dividindo {len(documentos)} documentos html em {tempo_final - tempo_inicio} segundos!\")\n",
        "print(f\"Quantidade de chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f0001e-86e8-4ecd-ec05-4237925d3d3a",
        "id": "SENyOAu30scC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando e dividindo 1 documentos html em 5.110030889511108 segundos!\n",
            "Quantidade de chunks: 375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostra alguns chunks. A sobreposição se encontra ao final e início de cada pedaço(chunk). A variável 'start_index' define onde começa o texto sem a sobreposição."
      ],
      "metadata": {
        "id": "lEpkjr3hcvGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, chunk in enumerate(chunks):\n",
        "  if i < 20:\n",
        "    # Divide o chunk pelo espaço em branco\n",
        "    tokens = chunk.page_content.split(\" \")\n",
        "\n",
        "    # Divide o chunk pelo tokenizador do BERT\n",
        "    tokens_bert = tokenizer_bert.tokenize(chunk.page_content)\n",
        "\n",
        "    print('chunk #',i, ' qtde char:', len(chunk.page_content),' qtde token:', len(tokens), ' qtde token bert:', len(tokens_bert), ' start_index:', chunk.metadata.get('start_index') )\n",
        "    print()\n",
        "    print(chunk.page_content)\n",
        "    print('-----------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "cFDYb8GJcriZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d6636d-5f99-4575-9de6-43611a81dc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk # 0  qtde char: 217  qtde token: 25  qtde token bert: 50  start_index: 16\n",
            "\n",
            "As vítimas algozes - Joaquim Manuel de Macedo\n",
            "\n",
            "\n",
            "\n",
            "Fonte: Biblioteca Digital de Literatura de Países Lusófonos\n",
            "\n",
            "LITERATURA BRASILEIRA \n",
            "Textos literários em\n",
            "meio eletrônico\n",
            "As\n",
            "Vítimas-Algozes, de Joaquim Manuel de Macedo\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 1  qtde char: 1922  qtde token: 308  qtde token bert: 497  start_index: 235\n",
            "\n",
            "Edição de base:\n",
            "Biblioteca Nacional – setor de obras digitalizadas\n",
            "ÍNDICE\n",
            "SIMEÃO, O CRIOULO\n",
            "PAI- RAIOL, O FEITICEIRO\n",
            "LUCINDA, A\n",
            "MUCAMA\n",
            "CONCLUSÃO\n",
            "I\n",
            "SIMEÃO, O CRIOULO\n",
            "I\n",
            "No interior e principalmente longe da vila, ou da\n",
            "freguesia e dos povoados há quase sempre uma venda perto da fazenda: é a\n",
            "parasita que se apega à árvore; pior que isso, é a inimiga hipócrita que rende\n",
            "vassalagem à sua vítima.\n",
            "A venda de que falo é uma taberna especialíssima\n",
            "que não poderia existir, manter-se, medrar em outras condições locais, e em\n",
            "outras condições do trabalho rural, e nem se confunde com a taberna regular que\n",
            "em toda parte se encontra, quanto mais com as casas de grande ou pequeno comércio,\n",
            "onde os lavradores ricos e pobres se provêem do que precisa a casa, quando não\n",
            "lhes é possível esperar pelas remessas dos seus consigna­tários ou fregueses.\n",
            "Essa parasita das fazendas e estabelecimentos agrícolas\n",
            "das vizinhanças facilmente se pode conhecer por suas feições e modos\n",
            "característicos, se nos é lícito dizer assim: uma se parece com todas e não há\n",
            "hipótese em que alguma delas, por mais dissimulada que seja, chegue a perder o\n",
            "cará­ter da família. \n",
            "É uma pequena casa de taipa e coberta de telha, tendo às\n",
            "vezes na frente varanda aberta pelos três lados, também coberta de telha e com\n",
            "o teto sustido por esteios fortes, mas rudes e ainda mesmo tortos; as paredes\n",
            "nem sempre são caiadas, o chão não tem assoalho nem ladrilho; quando há\n",
            "varanda, abrem-se para ela uma porta e uma janela; dentro está a ven­da: entre\n",
            "a porta e a janela encostado à parede um banco de pau, defronte um balcão tosco\n",
            "e no bojo ou no espaço que se vê além, grotesca armação de tábuas contendo\n",
            "garrafas, botijas, latas de tabaco em pó, a um canto algumas voltas de fumo em\n",
            "rolo e uma ruim manta de carne-seca. Eis a venda.\n",
            "Há muitas que nem chegam à opulência da que aí fica\n",
            "descrita; em todas porém aparece humilde no fundo do quase vazio bojo a porta\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 2  qtde char: 1956  qtde token: 316  qtde token bert: 494  start_index: 1824\n",
            "\n",
            "e no bojo ou no espaço que se vê além, grotesca armação de tábuas contendo\n",
            "garrafas, botijas, latas de tabaco em pó, a um canto algumas voltas de fumo em\n",
            "rolo e uma ruim manta de carne-seca. Eis a venda.\n",
            "Há muitas que nem chegam à opulência da que aí fica\n",
            "descrita; em todas porém aparece humilde no fundo do quase vazio bojo a porta\n",
            "baixa que comunica pelo corredor imundo com dois ou mais quartos escuros, onde\n",
            "se recolhem as pingues colheitas agrícolas do vendelhão que aliás não tem\n",
            "lavoura.\n",
            "A venda é pouco freqüentada à luz do sol nos dias\n",
            "de serviço; nunca porém, ou raramente se acha solitária: ainda nesses mesmos\n",
            "dias de santo dever do trabalho, homens ociosos, vadios e turbulentos jogam ao\n",
            "balcão com um baralho de cartas machucadas, enegrecidas e como oleosas desde a\n",
            "manhã até o fim da tarde, e é milagre faltar algum incansável tocador de viola;\n",
            "mas apenas chega a noite, começa a concorrência e ferve o negócio.\n",
            "Explorador das trevas protetoras dos vícios e do crime,\n",
            "o vendelhão baixo, ignóbil, sem consciência, paga com abuso duplo e escandaloso\n",
            "a garrafas de aguardente, a rolos de fumo, e a chorados vinténs o café, o\n",
            "açúcar e os cereais que os escravos furtam aos senhores; e cúmplice no furto\n",
            "efetuado pelos escravos, é ladrão por sua vez, roubando a estes nas medidas e\n",
            "no preço dos gêneros.\n",
            "A venda não dorme: às horas mortas da\n",
            "noite vêm os quilombolas escravos fugidos e acoitados nas florestas, trazer o\n",
            "tributo de suas depredações nas roças vizinhas ou distantes ao vendelhão que\n",
            "apura nelas segunda colheita do que não semeou e que tem sempre de reserva para\n",
            "os quilombolas recursos de alimentação de que eles não podem prescindir, e\n",
            "também não raras vezes a pólvora e o chumbo para a resistência nos casos de\n",
            "ataque aos quilombos.\n",
            "E o vendelhão é em regra a vigilância protetora do\n",
            "quilombola e o seu espião dissimulado que tem interesse em contrariar a\n",
            "polícia, ou as diligências dos senhores no encalço dos escravos fugidos.\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 3  qtde char: 1972  qtde token: 301  qtde token bert: 495  start_index: 3412\n",
            "\n",
            "os quilombolas recursos de alimentação de que eles não podem prescindir, e\n",
            "também não raras vezes a pólvora e o chumbo para a resistência nos casos de\n",
            "ataque aos quilombos.\n",
            "E o vendelhão é em regra a vigilância protetora do\n",
            "quilombola e o seu espião dissimulado que tem interesse em contrariar a\n",
            "polícia, ou as diligências dos senhores no encalço dos escravos fugidos.\n",
            "Desprezível e nociva durante o dia, a venda é\n",
            "esquálida, medonha, criminosa e atroz durante a noite: os escravos, que aí\n",
            "então se reúnem, embebedam-se, espancam-se, tornando-se muitos incapazes de\n",
            "trabalhar na manhã seguinte; misturam as rixas e as pancadas com a conversação\n",
            "mais indecente sob o caráter e a vida de seus senhores, cuja reputação é\n",
            "ultrajada ao som de gargalhadas selvagens: inspirados pelo ódio, pelo horror,\n",
            "pelos sofrimentos inseparáveis da escravidão, se expandem em calúnias terríveis\n",
            "que às vezes chegam até a honra das esposas e das filhas dos senhores; atiçam a\n",
            "raiva que todos eles têm dos feitores, contando histórias lúgubres de castigos\n",
            "exagerados e de cruelíssimas vinganças, a cuja idéia se habituam; em sua\n",
            "credulidade estúpida e ilimitada esses desgraçados escutam boquiabertos a\n",
            "relação dos prodígios do feitiço, e se emprazam para as reuniões noturnas dos\n",
            "feiticeiros; e uns finalmente aprendem com outros mais sabidos a conhecer\n",
            "plantas maléficas, raízes venenosas que produzem a loucura ou dão a morte, e\n",
            "tudo isto e muito mais ainda envolta com a embriaguez, com a desordem, com o\n",
            "quadro da abjeção e do desavergonhamento já natural nas palavras, nas ações,\n",
            "nos gozos do es­cravo.\n",
            "Aos domingos e nos dias santificados, a venda tem\n",
            "centuplicadas as suas glórias nefandas, aproveita a luz e as trevas, o dia e a\n",
            "noite, e por isso mesmo cada lavrador conta de menos na roça e demais na\n",
            "enfermaria al­guns escravos na manhã do dia que se segue.\n",
            "De ordinário, pelo menos muitas vezes, é nessas\n",
            "reuniões, é nesse foco de peste moral que se premeditam e planejam os crimes\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 4  qtde char: 1907  qtde token: 299  qtde token bert: 483  start_index: 5000\n",
            "\n",
            "Aos domingos e nos dias santificados, a venda tem\n",
            "centuplicadas as suas glórias nefandas, aproveita a luz e as trevas, o dia e a\n",
            "noite, e por isso mesmo cada lavrador conta de menos na roça e demais na\n",
            "enfermaria al­guns escravos na manhã do dia que se segue.\n",
            "De ordinário, pelo menos muitas vezes, é nessas\n",
            "reuniões, é nesse foco de peste moral que se premeditam e planejam os crimes\n",
            "que ensangüen­tam e alvoroçam as fazendas. Na hipótese de uma insurreição de\n",
            "escravos, a venda nunca seria alheia ao tremendo acontecimento.\n",
            "Todavia tolera-se a venda: o governo não pode\n",
            "ignorar, a polícia local sabe, os fazendeiros e lavradores conhecem e sentem\n",
            "que essa espelunca ignóbil é fonte de vícios e de crimes, manancial turvo e\n",
            "hediondo de pro­funda corrupção, constante ameaça à propriedade, patíbulo da\n",
            "reputa­ção, e em certos casos forja de arma assassina; porque é e será sempre o\n",
            "ponto de ajuntamento de escravos onde se conspire ou se inicie a conspi­ração;\n",
            "e ainda assim a venda subsiste e não há força capaz de aniquilá-la.\n",
            "Porquê?...\n",
            "É que se proibissem a venda, de que trato, se lhe\n",
            "fechassem a porta, se lhe destruíssem o teto, ela renasceria com outro nome, e,\n",
            "como quer que fosse, e, onde quer que fosse, havia de manter-se, embora\n",
            "dissimulada e abusivamente.\n",
            "A lógica é implacável.\n",
            "Não é possível que haja escravos sem todas as\n",
            "conseqüências escandalo­sas da escravidão: querer a úlcera sem o pus, o cancro\n",
            "sem a podridão é loucura ou capricho infantil.\n",
            "Perigosa e repugnante por certo, e ainda assim não das\n",
            "mais formidá­veis conseqüências da escravidão, a venda de que estou\n",
            "falando é inevitá­vel; porque nasce da vida, das condições, e das exigências\n",
            "irresistíveis da situação dos escravos.\n",
            "A venda é o espelho que retrata ao vivo o rosto e\n",
            "o espírito da escravi­dão.\n",
            "Se não fosse, se não se chamasse venda, teria\n",
            "outro e mil nomes no pa­tuá do escravo; seria uma casa no deserto, um sítio nas\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 5  qtde char: 1907  qtde token: 297  qtde token bert: 492  start_index: 6520\n",
            "\n",
            "mais formidá­veis conseqüências da escravidão, a venda de que estou\n",
            "falando é inevitá­vel; porque nasce da vida, das condições, e das exigências\n",
            "irresistíveis da situação dos escravos.\n",
            "A venda é o espelho que retrata ao vivo o rosto e\n",
            "o espírito da escravi­dão.\n",
            "Se não fosse, se não se chamasse venda, teria\n",
            "outro e mil nomes no pa­tuá do escravo; seria uma casa no deserto, um sítio nas\n",
            "brenhas; estaria na gruta da floresta, em um antro tomado às feras, mas onde\n",
            "iria sempre o escravo, o quilombola, vender o furto, embriagar-se, ultrajar a\n",
            "honra do senhor e de sua família, a quem detesta, engolfar-se em vícios, ouvir\n",
            "con­selhos envenenados, inflamar-se em ódio, e habituar-se à idéia do crime\n",
            "filho da vingança; porque o escravo, por melhor que seja tratado, é, em regra\n",
            "geral, pelo fato de ser escravo, sempre e natural e logicamente o pri­meiro e\n",
            "mais rancoroso inimigo de seu senhor.\n",
            "O escravo precisa dar expansão à sua raiva, que ferve\n",
            "incessante, e es­quecer por momentos ou horas as misérias e os tormentos\n",
            "insondáveis da escravidão; é na venda que ele se expande e esquece; aí o\n",
            "ódio fala licen­cioso e a aguardente afoga em vapores e no atordoamento a\n",
            "memória.\n",
            "Entretanto, a venda é horrível; é o recinto da\n",
            "assembléia selvagem dos escravos, onde se eleva a tribuna malvada da lascívia\n",
            "feroz, da difamação nojenta e do crime sem suscetibilidade de remorso; ali a\n",
            "matrona veneranda, a esposa honesta, a donzela-anjo são julgadas e medidas pela\n",
            "bitola da moralidade dos escravos; o aleive é aplaudido e sancionado como\n",
            "verdade provada, e o aleive se lança com as formas esquálidas da selvatiqueza\n",
            "que fala com a eloqüência do rancor sublimizado pelo álcool; ali se acendem\n",
            "fúrias contra os feitores e os senhores: ali se rouba a fazenda e se fazem\n",
            "votos ferozes pela morte daqueles que se detestam, porque, é im­possível\n",
            "negá-lo, são opressores.\n",
            "E não há para suprimir a venda, essa venda fatal,\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 6  qtde char: 1873  qtde token: 283  qtde token bert: 490  start_index: 8051\n",
            "\n",
            "verdade provada, e o aleive se lança com as formas esquálidas da selvatiqueza\n",
            "que fala com a eloqüência do rancor sublimizado pelo álcool; ali se acendem\n",
            "fúrias contra os feitores e os senhores: ali se rouba a fazenda e se fazem\n",
            "votos ferozes pela morte daqueles que se detestam, porque, é im­possível\n",
            "negá-lo, são opressores.\n",
            "E não há para suprimir a venda, essa venda fatal,\n",
            "que rouba, desmoraliza, corrompe, calunia e às vezes mata, senão um só, um\n",
            "único meio: é suprimir a escravidão.\n",
            "Não há; porque a venda está intimamente presa,\n",
            "imprescindivelmente adunada à vida do escravo; sem ela, os suicídios dos\n",
            "escravos espantariam pelas suas proporções.\n",
            "Onde houver fazendas, haverá por força a venda perversa,\n",
            "ameaçadora, infamíssima, como a tenho descrito e a conhecem todos, sem exceção,\n",
            "todos os lavradores.\n",
            "Não há rei sem trono, não há família sem lar, nem aves\n",
            "sem ninho, nem fera sem antro; o trono, o lar, o ninho, o antro do escravo é,\n",
            "antes da senzala, a venda.\n",
            "A venda, que vos parece apenas repugnante,\n",
            "corruptora, ladra e infa­me, é, ainda mais, formidável e atroz; mas em todos\n",
            "esses atributos digna, legítima filha da escravidão, que a gerou, criou,\n",
            "sustenta, impõe, e que há de mantê-la arraigada à sua existência.\n",
            "É um mal absolutamente dependente, porém inseparável de\n",
            "outro mal; não é causa, é efeito; não é árvore, é fruto de árvore.\n",
            "Se quiserdes suprimir a venda-inferno, haveis de\n",
            "suprimir primeiro a escravidão-demônio.\n",
            "II\n",
            "Era em uma dessas vendas sinistras como a que\n",
            "acabamos de descrever. \n",
            "O sítio era solitário; a estrada rompia pelo meio vasta\n",
            "floresta que cortava sinuosa, e, descendo declive suave, ia\n",
            "atravessar tênue corrente d’água alimentada por brejal vizinho e de novo se\n",
            "perdia, como embe­bendo-se no seio do bosque.\n",
            "A venda mostrava-se triste à beira da estrada,\n",
            "que em sua frente se alargava cerca de seis ou oito braças; tinha ao lado\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 7  qtde char: 1934  qtde token: 302  qtde token bert: 481  start_index: 9542\n",
            "\n",
            "acabamos de descrever. \n",
            "O sítio era solitário; a estrada rompia pelo meio vasta\n",
            "floresta que cortava sinuosa, e, descendo declive suave, ia\n",
            "atravessar tênue corrente d’água alimentada por brejal vizinho e de novo se\n",
            "perdia, como embe­bendo-se no seio do bosque.\n",
            "A venda mostrava-se triste à beira da estrada,\n",
            "que em sua frente se alargava cerca de seis ou oito braças; tinha ao lado\n",
            "direito o brejal a esten­der-se para trás, e ao esquerdo e pegada à casa uma\n",
            "rude tranqueira de pau, dando entrada para um terreiro imundo, que se adiantava\n",
            "pouco além da cozinha. Não havia criação no terreiro; apenas a ele se recolhiam\n",
            "à noite um porco, que chafurdava na lama, e um casal de patos, que grasnavam no\n",
            "brejo.\n",
            "A venda se isolava na solidão, mas não longe de\n",
            "fazendas e sítios, que se anunciavam de madrugada pelo cantar dos galos, à\n",
            "tarde pelo mugir dos bois, à noite pelo latir dos cães.\n",
            "Os cavaleiros e viandantes que passavam às vezes durante\n",
            "o dia, não se lembravam nunca de chegar-se ou parar àquela venda desprezível,\n",
            "onde em compensação faziam sempre estação demorada os escravos carreiros ou\n",
            "tropeiros que iam ou voltavam, conduzindo gêneros.\n",
            "Entretanto, aquele teto miserável, albergue de vícios e\n",
            "torpezas, jamais se achava em abandono de fregueses.\n",
            "Há poucos anos, em um dia calmoso do mês de fevereiro,\n",
            "viam-se às três horas da tarde nessa venda certas figuras, formando um\n",
            "quadro quase constantemente ali observado com insignificantes modificações até\n",
            "a hora do negro concurso noturno.\n",
            "Para dentro do balcão estava um menino de doze anos, de\n",
            "pés no chão, vestido de calças e camisa que desde um mês não mudava, e cuja cor\n",
            "e qualidade do pano escapariam ao mais teimoso exame; era o caixeiro mandrião,\n",
            "e já perdido pela desmoralização, pela incontinência da pala­vra e pela\n",
            "convivência com os vadios e os escravos. À porta da venda via-se em pé a\n",
            "olhar a estrada um homem de meia-idade, cabeludo, amarelo, em mangas de camisa\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 8  qtde char: 1915  qtde token: 298  qtde token bert: 491  start_index: 11094\n",
            "\n",
            "pés no chão, vestido de calças e camisa que desde um mês não mudava, e cuja cor\n",
            "e qualidade do pano escapariam ao mais teimoso exame; era o caixeiro mandrião,\n",
            "e já perdido pela desmoralização, pela incontinência da pala­vra e pela\n",
            "convivência com os vadios e os escravos. À porta da venda via-se em pé a\n",
            "olhar a estrada um homem de meia-idade, cabeludo, amarelo, em mangas de camisa\n",
            "com o colarinho desabotoado, o peito à mostra, e calçando grandes tamancos: era\n",
            "o vendelhão.\n",
            "Em uma extremidade do balcão sentava-se um homem avelhantado,\n",
            "tendo as pernas pendidas, os pés descalços, os vestidos remendados, um velho\n",
            "chapéu de palha na cabeça, e ao peito uma viola, em que tocava de contínuo as\n",
            "músicas rudes dos fados. Na outra extremidade do balcão quatro sujeitos moços\n",
            "quase todos, um ainda imberbe, todos quatro mais ou menos miseravelmente\n",
            "vestidos, jogavam o pacau, rixando a todo mo­mento, e não se poupando\n",
            "acusações de furtos e de fraude no jogo.\n",
            "Um último freguês enfim, figura sinistra, tendo olhos de\n",
            "tigre, boca, por assim dizer, sem lábios, e com imensa barba malcuidada,\n",
            "parecia dor­mir estendido em um banco de pau defronte do balcão.\n",
            "De espaço em espaço a aguardente inspirava o tocador de\n",
            "viola e ani­mava os jogadores.\n",
            "Às quatro horas da tarde um cavalo, correndo à\n",
            "desfilada, veio estacar à porta da venda, pondo-se o cavaleiro de um\n",
            "salto no chão.\n",
            "O cavaleiro era um crioulo escravo ainda muito jovem.\n",
            "– Oh!... O grande Simeão!... – exclamou o vendelhão,\n",
            "abraçando o escravo.\n",
            "– Uma pinga que estou com muita pressa – disse este, e\n",
            "correu para dentro da venda.\n",
            "Simeão recebeu logo um copo cheio de aguardente, que\n",
            "bebeu de uma vez, atirando o resto à cara do menino, que o servira.\n",
            "III\n",
            "Simeão devia ter vinte anos: era um crioulo de raça pura\n",
            "africana, mas cujos caracteres físicos aliás favoravelmente modificados pelo\n",
            "clima e pe­la influência natural do país onde nascera, não tinham sido ainda\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 9  qtde char: 2139  qtde token: 321  qtde token bert: 500  start_index: 12645\n",
            "\n",
            "correu para dentro da venda.\n",
            "Simeão recebeu logo um copo cheio de aguardente, que\n",
            "bebeu de uma vez, atirando o resto à cara do menino, que o servira.\n",
            "III\n",
            "Simeão devia ter vinte anos: era um crioulo de raça pura\n",
            "africana, mas cujos caracteres físicos aliás favoravelmente modificados pelo\n",
            "clima e pe­la influência natural do país onde nascera, não tinham sido ainda\n",
            "afeiados pelos serviços rigorosos da escravidão, embora ele fosse escravo.\n",
            "Havia em seus modos a expansão que só parece própria do\n",
            "homem li­vre: ele não tinha nem as mãos calejadas, nem os pés esparramados do\n",
            "ne­gro trabalhador de enxada: era um escravo de cabelos penteados, vestido com\n",
            "asseio e certa faceirice, calçado, falando com os vícios de\n",
            "linguagem triviais no campo, mas sem a bruteza comum na gente da sua condição;\n",
            "até certo ponto, pois, aceito, apadrinhado, protegido e acariciado pela fa­mília\n",
            "livre, pelo amor dos senhores.\n",
            "A história de Simeão tem mil histórias irmãs até aos\n",
            "vinte anos, que ele conta; há de, portanto, trazer à memória mil histórias,\n",
            "como a sua, cheia de desgostos e de ressentimentos de ingratidão, que aliás,\n",
            "sem o pensar, os benfeitores cimentam. A história que vai seguir-se depois dos\n",
            "vinte anos talvez lembre alguma infelizmente mais ou menos semelhante, e cu­jo\n",
            "horror é somente um dos frutos e dos horrores da escravidão.\n",
            "Sementeira de venenosos espinhos, a escravidão não pode\n",
            "produzir flo­res inocentes.\n",
            "A história de Simeão ainda não criminoso é simples:\n",
            "muitos dos leito­res deste romance a encontrarão realizada, viva,\n",
            "eloqüentemente exposta no seio de seu lar doméstico.\n",
            "Domingos Caetano teve de sua mulher muito e bem\n",
            "merecidamente amada uma filha que satisfizera os doces votos de ambos.\n",
            "Angélica, a no­bre esposa e virtuosa mulher, não pôde ter a dita de amamentar o\n",
            "seu an­jo, e confiou-o aos peitos de uma escrava que acabava de ser mãe como\n",
            "ela: a escrava que amamentara dois filhos, o próprio e o da senhora, morreu\n",
            "dois anos depois, e Angélica pagou-lhe a amamentação da sua queri­da Florinda,\n",
            "criando com amor maternal o crioulinho Simeão, colaço de sua filha.\n",
            "A compaixão e o reconhecimento em breve se transformaram\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 10  qtde char: 2048  qtde token: 312  qtde token bert: 491  start_index: 14428\n",
            "\n",
            "seu an­jo, e confiou-o aos peitos de uma escrava que acabava de ser mãe como\n",
            "ela: a escrava que amamentara dois filhos, o próprio e o da senhora, morreu\n",
            "dois anos depois, e Angélica pagou-lhe a amamentação da sua queri­da Florinda,\n",
            "criando com amor maternal o crioulinho Simeão, colaço de sua filha.\n",
            "A compaixão e o reconhecimento em breve se transformaram\n",
            "em ver­dadeira afeição: o crioulo era esperto e engraçado, começou fazendo rir,\n",
            "acabou fazendo-se amar. Simeão divertia, dava encanto às travessuras de\n",
            "Florinda: Domingos Caetano e Angélica o amaram em dobro por isso.\n",
            "Até os oito anos de idade Simeão teve prato à mesa e\n",
            "leito no quarto de seus senhores, e não teve consciência de sua condição de\n",
            "escravo. Depois dos oito anos apenas foi privado da mesa e do quarto em comum;\n",
            "conti­nuou, porém, a receber tratamento de filho adotivo, mas criado com amor\n",
            "desmazelado e imprudente, e cresceu enfim sem hábito de traba­lho, abusando\n",
            "muitas vezes da fraqueza dos senhores, sem atingir a digni­dade de homem livre,\n",
            "e sem reconhecer nem sentir a absoluta submissão do escravo.\n",
            "Era o tipo mais perfeito do crioulo, cria estimada da\n",
            "família.\n",
            "IV\n",
            "Mais de uma vez parentes e amigos de Domingos Caetano e\n",
            "Angélica disseram a um ou outro, mostrando Simeão:\n",
            "– Estão criando um inimigo: a regra não falha.\n",
            "E Domingos respondia:\n",
            "– Coitado! Ele é tão bom!\n",
            "E Angélica dizia sorrindo-se:\n",
            "É impossível que nos seja ingrato.\n",
            "– Ainda não houve um que o não fosse! – tornavam-lhes\n",
            "debalde; porque os senhores de Simeão nem por essas já triviais advertências\n",
            "menos condescendentes e afetuosos se mostravam com o seu crioulo estimado.\n",
            "Breve reflexão de passagem.\n",
            "As apreensões da ingratidão e da inimizade desses\n",
            "escravos, crias predi­letas aquecidas no seio da família, têm por certo o\n",
            "fundamento da mais triste experiência; mas a sanção da regra sem o estudo e\n",
            "reconhecimento da causa do mal tenderia a fazer apagar as santas inspirações da\n",
            "caridade, e a empedernir os corações de todos os senhores de escravos.\n",
            "Fora absurdo pretender que a ingratidão às vezes até\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 11  qtde char: 2072  qtde token: 317  qtde token bert: 500  start_index: 16073\n",
            "\n",
            "As apreensões da ingratidão e da inimizade desses\n",
            "escravos, crias predi­letas aquecidas no seio da família, têm por certo o\n",
            "fundamento da mais triste experiência; mas a sanção da regra sem o estudo e\n",
            "reconhecimento da causa do mal tenderia a fazer apagar as santas inspirações da\n",
            "caridade, e a empedernir os corações de todos os senhores de escravos.\n",
            "Fora absurdo pretender que a ingratidão às vezes até\n",
            "profundamente perversa dos crioulos amorosamente criados por seus senhores é\n",
            "neles ina­ta ou condição natural da sua raça: a fonte do mal, que é mais negra\n",
            "do que a cor desses infelizes, é a escravidão, a consciência desse estado violen­ta\n",
            "e barbaramente imposto, estado lúgubre, revoltante, condição ignóbil, mãe do\n",
            "ódio, pústula encerradora de raiva, pantanal dos vícios mais tor­pes que\n",
            "degeneram, infeccionam, e tornam perverso o coração da vítima, o coração do\n",
            "escravo.\n",
            "No amor dos senhores o crioulo estimado viu, sentiu,\n",
            "gozou os reflexos das flamas vivificantes, generosas, sagradas da liberdade:\n",
            "mas vem um dia em que ele se reconhece escravo, coisa e não homem, apesar da\n",
            "afeição, das condescendências, dos caridosos benefícios do senhor – amigo, da\n",
            "se­nhora – segunda mãe; vem a primeira hora sinistra em que ele, que até então\n",
            "vivera em sonhos e ilusões, desperta com a certeza horrível de que é um\n",
            "condenado daquém-berço; condenado sem crime; tendo alma e con­siderado simples\n",
            "matéria ambulante; coisa, animal, que se vende, como a casa, como o boi e como\n",
            "a besta; finalmente miserável e perpétuo des­terrado em deserto sem horizonte,\n",
            "tendo vida e não vivendo para si, dese­jando sem esperanças, não possuindo de\n",
            "seu nem o pleno direito dos três amores mais santos: o de filho, o de esposo, e\n",
            "o de pai; máquina para ca­var com a enxada, homem desnaturado, miséria\n",
            "respirante e movente que os próprios cães distinguem pela marca do desprezo\n",
            "social.\n",
            "O crioulo escravo e estimado, por isso mesmo que tem\n",
            "mais aguçada a inteligência, e por isso mesmo que deram-lhe as mostras dos\n",
            "gozos e da superioridade, mas não lhe deram a condição e a educação próprias do\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 12  qtde char: 2073  qtde token: 318  qtde token bert: 497  start_index: 17783\n",
            "\n",
            "o de pai; máquina para ca­var com a enxada, homem desnaturado, miséria\n",
            "respirante e movente que os próprios cães distinguem pela marca do desprezo\n",
            "social.\n",
            "O crioulo escravo e estimado, por isso mesmo que tem\n",
            "mais aguçada a inteligência, e por isso mesmo que deram-lhe as mostras dos\n",
            "gozos e da superioridade, mas não lhe deram a condição e a educação próprias do\n",
            "homem livre, pesa melhor que os escravos brutais o preço e o encanto da\n",
            "verdadeira liberdade; no meio dos benefícios compreende que lhe falta um que\n",
            "vale mais do que todos os outros somados e multiplicados; feliz pelos favores\n",
            "que recebe, pelos dons da afeição de que é objeto, esbarra sempre diante da\n",
            "realidade da escravidão, que o abate, avilta e moral­mente o aniquila: deseja e\n",
            "não tem, quer e não pode, sonha e não realiza o bem supremo da terra, escravo\n",
            "se reconhece e bebe o ódio, os maus cos­tumes, o veneno, a perversidade da\n",
            "escravidão.\n",
            "O crioulo escravo e estimado, em quem o amor e as\n",
            "condescendências do senhor animam e atiçam expansões naturais do amplo gozo da\n",
            "liberda­de, mistura nos dias da reflexão mais sombria e triste a lembrança dos\n",
            "sa­bores do reflexo da liberdade com a ameaça e os negros horrores da escra­vidão;\n",
            "habituado à impunidade garantida pela afeição, ousa muito e abu­sa ainda mais;\n",
            "como predileto da família, e escravo, portanto infecciona­do de todos os vícios\n",
            "e ferozes impulsos da madre-fera escravidão, insolen­te e malcriado, nem\n",
            "perfeitamente livre, nem absolutamente escravo, bom juiz odiento, pois que\n",
            "conhece as duas condições, e da melhor é bas­tardo, e da pior legítimo\n",
            "filho, o crioulo escravo e estimado de seu se­nhor, torna-se em breve tempo\n",
            "ingrato e muitas vezes leva a ingratidão a perversidade, porque é escravo.\n",
            "Mas a sua ingratidão e a sua perversidade não se\n",
            "explicam pela nature­za da raça, o que seria absurdo; explicam-se pela condição\n",
            "de escravo, que corrompe e perverte o homem.\n",
            "O\n",
            "crioulo amorosamente criado pela família dos senhores seria talvez o seu melhor\n",
            "amigo, se não fosse escravo.\n",
            "V\n",
            "Ninguém poderia ter marcado, nem o próprio Simeão seria\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 13  qtde char: 1936  qtde token: 290  qtde token bert: 499  start_index: 19514\n",
            "\n",
            "Mas a sua ingratidão e a sua perversidade não se\n",
            "explicam pela nature­za da raça, o que seria absurdo; explicam-se pela condição\n",
            "de escravo, que corrompe e perverte o homem.\n",
            "O\n",
            "crioulo amorosamente criado pela família dos senhores seria talvez o seu melhor\n",
            "amigo, se não fosse escravo.\n",
            "V\n",
            "Ninguém poderia ter marcado, nem o próprio Simeão seria\n",
            "capaz de determinar o dia em que lhe toldara as alegrias do coração inocente a\n",
            "pri­meira gota de fel destilado pela consciência da sua escravidão. Havia para\n",
            "ele na casa de seus amorosos senhores um céu e um inferno: na sala o néctar da\n",
            "predileção e da amizade, na cozinha o veneno da inveja e o golfão dos vícios:\n",
            "na cozinha a negra má e impiedosa castigou-lhe as travessuras e exigências\n",
            "incômodas e apadrinhadas pelos senhores, repetindo-lhe mil vezes:\n",
            "– Tu és escravo como eu.\n",
            "E o negro enfezado e ruim perseguia o crioulinho\n",
            "estimado com a ameaça lúgubre de um futuro tormentoso:\n",
            "– Brinca para aí, pobre coitado! Hás de ver como é bom o\n",
            "chicote, quando cresceres...\n",
            "E pouco a pouco Simeão abalado, incessantemente\n",
            "influenciado pela inveja e pelas maldades da cozinha, deixou-se tomar de um\n",
            "constrangi­mento leve, mas invencível, que foi o primeiro sinal da triste\n",
            "suspeita do abismo que o separava dos senhores.\n",
            "A cozinha foi sempre adiantando a sua obra: quando\n",
            "conseguiram convencer, compenetrar o crioulinho da baixeza, da miséria da sua\n",
            "condi­ção, as escravas passaram a preparar nele o inimigo dos seus amantes pro­tetores:\n",
            "ensinaram-o a espiar a senhora, a mentir-lhe, a atraiçoá-la, ouvindo-lhe as\n",
            "conversas com o senhor para contá-las na cozinha; desmo­ralizaram-no com as\n",
            "torpezas da linguagem mais indecente, com os qua­dros vivos de gozos\n",
            "esquálidos, com o exemplo freqüente do furto e da embriaguez, e com a lição\n",
            "insistente do ódio concentrado aos senhores.\n",
            "E a sala ajudou sem o pensar, sem o querer, a obra da\n",
            "cozinha.\n",
            "Domingos Caetano e Angélica não destinavam Simeão para\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 14  qtde char: 2009  qtde token: 290  qtde token bert: 491  start_index: 21067\n",
            "\n",
            "conversas com o senhor para contá-las na cozinha; desmo­ralizaram-no com as\n",
            "torpezas da linguagem mais indecente, com os qua­dros vivos de gozos\n",
            "esquálidos, com o exemplo freqüente do furto e da embriaguez, e com a lição\n",
            "insistente do ódio concentrado aos senhores.\n",
            "E a sala ajudou sem o pensar, sem o querer, a obra da\n",
            "cozinha.\n",
            "Domingos Caetano e Angélica não destinavam Simeão para\n",
            "trabalha­dor de enxada, e não o fizeram aprender ofício algum, nem lhe deram ta­refa,\n",
            "e ocupação na fazenda: abandonando-o à quase completa ociosida­de, tolerando\n",
            "seus abusos com fraqueza e cega condescendência, e, o que é pior, simulando às\n",
            "vezes exagerada severidade esquecida logo depois, ameaçando sem realizar jamais\n",
            "a ameaça do castigo, dando enfim ao crioulo facilidades para o passeio, não\n",
            "raramente dinheiro para suas des­pesas fúteis, amando-o como filho adotivo, e\n",
            "conservando-o escravo, sem o querer, sem o pensar, auxiliaram as depravações da\n",
            "cozinha que perver­teram o vadio da fazenda.\n",
            "E, maior imprudência ainda, ora Domingos, ora Angélica,\n",
            "cada qual por sua vez sorrindo ao pequeno Simeão, e falando aos amigos que, por\n",
            "favor e agrado a eles, o tratavam com prazenteiros modos, dizia sem cau­tela:\n",
            "– Este não será de outro senhor.\n",
            "E a promessa contida nas palavras referentes ao escravo\n",
            "ainda pequeno foi por muitas bocas traduzida com acerto ao escravo mais tarde\n",
            "jovem, por turvo juízo que encerrava esperança dependente de morte.\n",
            "Diziam a Simeão:\n",
            "– Feliz rapaz! Em seu testamento teu senhor te deixa forro.\n",
            "E, por aborrecimento da escravidão, pelo anelo da\n",
            "liberdade completa, pelo encanto de chegar a ser dono de si próprio, Simeão\n",
            "escravo era já in­grato; porque não pensava mais que a morte de seu benfeitor\n",
            "fosse um su­cesso lamentável.\n",
            "A venda rematou a obra começada pela cozinha e\n",
            "auxiliada pela sala.\n",
            "Não podendo ter parte nos banquetes, nas reuniões\n",
            "festivas, nos diver­timentos da sociedade livre, vendo-os de longe,\n",
            "invejando-os, querendo arremedá-los, Simeão que pairava em uma condição média,\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 15  qtde char: 1992  qtde token: 283  qtde token bert: 500  start_index: 22704\n",
            "\n",
            "escravo era já in­grato; porque não pensava mais que a morte de seu benfeitor\n",
            "fosse um su­cesso lamentável.\n",
            "A venda rematou a obra começada pela cozinha e\n",
            "auxiliada pela sala.\n",
            "Não podendo ter parte nos banquetes, nas reuniões\n",
            "festivas, nos diver­timentos da sociedade livre, vendo-os de longe,\n",
            "invejando-os, querendo arremedá-los, Simeão que pairava em uma condição média,\n",
            "mas artifi­cial, inconseqüente e falsa entre as flores da liberdade que não\n",
            "podia co­lher de todo e os espinhos da escravidão que embora não dilacerassem,\n",
            "es­picaçavam-lhe o coração, desceu da situação híbrida para o fundo do abis­mo:\n",
            "do fado da senzala da fazenda, passou depressa aos ajuntamentos da venda, e\n",
            "convivendo ali com os escravos mais brutais e corruptos, e com os vadios,\n",
            "turbulentos e viciosos das vizinhanças entregou-se a todos os de­boches, e se\n",
            "fez sócio ativo do jogo aladroado, da embriaguez ignóbil e da luxúria mais\n",
            "torpe.\n",
            "Simeão\n",
            "foi desde então perfeito escravo.\n",
            "VI\n",
            "A\n",
            "necessidade da alimentação dos vícios torna o vadio ladrão.\n",
            "Domingos Caetano e Angélica fatigaram-se de duvidar, e\n",
            "cederam à evidência, reconhecendo que Simeão lhes furtava dinheiro e objetos de\n",
            "valor; mas em vez de castigá-lo com severidade, fracos ainda, quiseram ver no\n",
            "crime apenas uma extravagância da mocidade, e limitaram-se a re­preender com\n",
            "aspereza, e a impedir durante algumas semanas as saídas de Simeão.\n",
            "A insuficiência do castigo serviu somente para irritar o\n",
            "crioulo que, res­sentido da privação de seus prazeres, maldisse dos senhores na\n",
            "cozinha, recrudescendo-lhe a raiva com as zombarias e as provocações dos par­ceiros.\n",
            "A escravidão já tinha com o seu cortejo lógico e quase\n",
            "sempre infalível de todos os sentimentos ruins, de todas as paixões ignóbeis,\n",
            "estragado o crioulo que talvez houvesse nascido com felizes disposições\n",
            "naturais: o ódio aos senhores já estava incubado na alma do escravo; só faltava\n",
            "para desenvolvê-lo o calor mais forte da ação do domínio absoluto que desu­maniza\n",
            "o homem a ele sujeito.\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 16  qtde char: 1870  qtde token: 281  qtde token bert: 491  start_index: 24307\n",
            "\n",
            "A escravidão já tinha com o seu cortejo lógico e quase\n",
            "sempre infalível de todos os sentimentos ruins, de todas as paixões ignóbeis,\n",
            "estragado o crioulo que talvez houvesse nascido com felizes disposições\n",
            "naturais: o ódio aos senhores já estava incubado na alma do escravo; só faltava\n",
            "para desenvolvê-lo o calor mais forte da ação do domínio absoluto que desu­maniza\n",
            "o homem a ele sujeito.\n",
            "Simeão acabava de contar dezenove anos e nunca houvera\n",
            "sofrido casti­go algum corporal. Vira por vezes o quadro repulsivo dessas\n",
            "punições que são indeclináveis nas fazendas, mas nem por isso menos\n",
            "contristadoras, e de cada vez que os vira, experimentara abalo profundo e\n",
            "seguido de me­lancolia que durava horas: não falava, não manifestava por\n",
            "palavras ou queixas o que sentia; mas dentro de si estava dizendo: “e também eu\n",
            "posso ser castigado assim! \n",
            "Entretanto Domingos e Angélica eram senhores bons e\n",
            "humanos.\n",
            "Um dia quase ao pôr-do-sol Florinda, que aliás protegia\n",
            "muito Simeão, surpreendeu-o, saindo do quarto de seus pais, e no ato de\n",
            "esconder um objeto no bolso.\n",
            "O crioulo aproveitara a ocasião, em que Angélica e\n",
            "Florinda tinham ido passear à horta, para invadir o quarto do senhor, donde\n",
            "furtara uma corrente de ouro que dois dias antes Domingos comprara a um\n",
            "vendedor de jóias.\n",
            "– Ainda um furto, Simeão!... – exclamou Florinda que de\n",
            "súbito acabava de chegar.\n",
            "– E quem lhe disse que eu furtei?... – perguntou\n",
            "audaciosamente o crioulo.\n",
            "A moça avançou um passo para o escravo e disse-lhe:\n",
            "– Entrega-me o que furtaste: eu não direi nada e te\n",
            "perdoarei... tu és doido e queres ser desgraçado...\n",
            "Em vez de obedecer sem insolência e de curvar-se\n",
            "agradecido diante do anjo do perdão, o crioulo recuou, dizendo em alta voz:\n",
            "– É mentira! Eu não furtei.\n",
            "À palavra mentira, Florinda estremeceu ferida pelo\n",
            "insulto.\n",
            "– Atrevido! – bradou.\n",
            "Uma escrava correu ao grito da senhora-moça.\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 17  qtde char: 1827  qtde token: 281  qtde token bert: 483  start_index: 25898\n",
            "\n",
            "Em vez de obedecer sem insolência e de curvar-se\n",
            "agradecido diante do anjo do perdão, o crioulo recuou, dizendo em alta voz:\n",
            "– É mentira! Eu não furtei.\n",
            "À palavra mentira, Florinda estremeceu ferida pelo\n",
            "insulto.\n",
            "– Atrevido! – bradou.\n",
            "Uma escrava correu ao grito da senhora-moça.\n",
            "– Tira do bolso desse miserável o que ele acaba de\n",
            "furtar!\n",
            "A escrava ia cumprir a ordem; mas Simeão repeliu-a, e\n",
            "tirando a cor­rente do bolso, lançou-a de longe à parceira com movimento tão\n",
            "desastrado ou com tal propósito de ofensa, que a corrente foi cair aos pés de\n",
            "Florinda.\n",
            "Nesse momento entravam Angélica e Domingos que chegara\n",
            "da roça, e tinha ainda na mão o açoite do cavalo.\n",
            "– Que foi isto? – perguntou ele.\n",
            "Florinda era uma santa: compadeceu-se do crioulo e\n",
            "calou-se; a escrava, porém, obedeceu e falou.\n",
            "Ouvindo a relação do caso e do insulto feito à filha,\n",
            "Domingos Caeta­no, tomado de justa cólera, levantou o açoite e descarregou-o\n",
            "com vivaci­dade sobre as costas de Simeão.\n",
            "Seis vezes e repetidamente os golpes se tinham repetido,\n",
            "quando Flo­rinda em pranto arrancou o açoite da mão de seu pai.\n",
            "Simeão recebera as chicotadas imóvel, sem soltar um\n",
            "gemido, sem der­ramar uma lágrima, e sem pronunciar uma só palavra de\n",
            "arrependimento ou desculpa, e quando privado do açoite Domingos Caetano o\n",
            "ameaçava ainda, ele com os olhos turvos e como em olhar febril mediu de alto a\n",
            "bai­xo o senhor que tão justamente o castigara, e a senhora-moça que tão pie­dosa\n",
            "correra a poupá-lo a maior e bem merecida punição.\n",
            "Foi nesse dia que se desenvolveu o ódio do escravo. O\n",
            "ingrato se tornou odiento e inimigo figadal de seus benfeitores.\n",
            "Até os dezenove anos corpo virgem de castigos, Simeão\n",
            "vira enfim rea­lizada a sua terrível e sombria apreensão: também ele tinha\n",
            "provado o açoite da escravidão.\n",
            "O pervertido crioulo não pesou nem por instantes as\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 18  qtde char: 1871  qtde token: 291  qtde token bert: 498  start_index: 27343\n",
            "\n",
            "correra a poupá-lo a maior e bem merecida punição.\n",
            "Foi nesse dia que se desenvolveu o ódio do escravo. O\n",
            "ingrato se tornou odiento e inimigo figadal de seus benfeitores.\n",
            "Até os dezenove anos corpo virgem de castigos, Simeão\n",
            "vira enfim rea­lizada a sua terrível e sombria apreensão: também ele tinha\n",
            "provado o açoite da escravidão.\n",
            "O pervertido crioulo não pesou nem por instantes as\n",
            "proporções do desrespeito audacioso, da injúria com que ofendera a\n",
            "senhora-moça, não se lembrou da reincidência do seu crime de furto, esqueceu,\n",
            "desprezou o generoso movimento com que Florinda o acudira, nem mesmo pareceu\n",
            "ter idéia da dor das chicotadas; mas a seus olhos só e incessante se mostra­va\n",
            "a imagem do açoite, quando atirado no ar, a cair-lhe sobre as espáduas, e a\n",
            "imprimir-lhe nas espáduas a marca da última abjeção.\n",
            "Em falta de pundonor e de vergonha, que a escravidão não\n",
            "comporta, o escravo tem o rancor e o desejo da vingança. \n",
            "Nas pontas do açoite está o emblema do rancor do\n",
            "escravo: às vezes há nas pontas do açoite marcas de sangue.\n",
            "Tudo isto é repugnante, é repulsivo, é horrível; mas\n",
            "tudo isto se acha intimamente ligado com a escravidão, e absolutamente\n",
            "inseparável dela.\n",
            "Onde há escravos é força que haja açoite.\n",
            "Onde há açoite é força que haja ódio.\n",
            "Onde há ódio é fácil haver vingança e crimes.\n",
            "Simeão odiava pois seus senhores, a quem devia os\n",
            "cuidados zelosos de sua infância, amizade e proteção, e cegas condescendências\n",
            "que tanto lhe haviam suavizado a vida de escravo sem sofrimentos de escravo.\n",
            "Simeão odiava o senhor, que o castigara com o açoite,\n",
            "odiava a senhora que nem sequer o castigara, e, inexplicável nuança ou\n",
            "perversão insensata do ódio, odiava mais que a todos Florinda, a senhora-moça,\n",
            "a santa meni­na que ofendida, insultada por ele, tão pronta lhe perdoara a\n",
            "ofensa, tão prestes se precipitara a livrá-lo do açoite.\n",
            "O negro escravo é assim.\n",
            "-----------------------------------------------------------------------\n",
            "chunk # 19  qtde char: 1870  qtde token: 285  qtde token bert: 500  start_index: 28908\n",
            "\n",
            "odiava a senhora que nem sequer o castigara, e, inexplicável nuança ou\n",
            "perversão insensata do ódio, odiava mais que a todos Florinda, a senhora-moça,\n",
            "a santa meni­na que ofendida, insultada por ele, tão pronta lhe perdoara a\n",
            "ofensa, tão prestes se precipitara a livrá-lo do açoite.\n",
            "O negro escravo é assim.\n",
            "Se o não\n",
            "quereis assim, acabai com a escravidão.\n",
            "VII\n",
            "Eis aí quem era, e o que era o crioulo que, trazendo o\n",
            "cavalo em que montava a correr à desfilada, acabava de chegar à venda.\n",
            "Tinha ele virado o seu copo de aguardente, cujas gotas\n",
            "restantes atirara ao rosto do menino caixeiro.\n",
            "Sem fazer caso da palavrosa represália do menino que se\n",
            "pagava da dor dos olhos tocados pela aguardente, dizendo-lhe injúrias,\n",
            "dirigiu-se ao grupo de jogadores do pacau e disse-lhes:\n",
            "– Se vocês têm dinheiro, entro no jogo; mas há de ser\n",
            "jogo de arrebentar logo; porque estou apressado...\n",
            "– Quanto trazes?\n",
            "– Cinco mil-réis... são cinco paradas; quem topa?\n",
            "Os jogadores hesitaram; dois deles, porém, fizeram\n",
            "sociedade contra Simeão, e travaram a batalha dos cinco mil-réis.\n",
            "Os outros dois, já depenados de seus magros vinténs,\n",
            "ficaram a olhar.\n",
            "O vendelhão e o homem barbudo que dormia, e então\n",
            "despertou, vieram apreciar o jogo de grossas paradas.\n",
            "As cartas contrariaram a pressa de Simeão, equilibrando\n",
            "durante uma hora bem longa a fortuna dos contendores: por fim o crioulo, que\n",
            "não se deixava enganar pelos jogadores mais fraudulentos e melhores\n",
            "empalmadores, ganhou os cinco mil-réis aos dois associados, e não vendo\n",
            "dinheiro no balcão, voltou-lhes as costas.\n",
            "– Que diabo de crioulo! – disse um dos jogadores\n",
            "infelizes. – Ou ele conhece as cartas, ou fez-se parceiro de S. Benedito nas\n",
            "horas do jogo. É o santo negro que ajuda os diabos negros!\n",
            "Simeão pôs-se a rir e respondeu:\n",
            "– Vocês não podem comigo hoje; estou em boa lua de\n",
            "felicidade: o velho lá ficou estirando as pernas...\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maior_chunk_token = 0\n",
        "maior_chunk_token_bert = 0\n",
        "maior_chunk_character = 0\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    # Divide o chunk pelo espaço em branco\n",
        "    tokens = chunk.page_content.split(\" \")\n",
        "\n",
        "    # Divide o chunk pelo tokenizador do BERT\n",
        "    tokens_bert = tokenizer_bert.tokenize(chunk.page_content)\n",
        "\n",
        "    print('chunk #',i, ' qtde char :', len(chunk.page_content),' qtde token :', len(tokens),' qtde token bert:', len(tokens_bert) )\n",
        "\n",
        "    # Procura os maiores valores\n",
        "    if len(tokens) > maior_chunk_token:\n",
        "      maior_chunk_token = len(tokens)\n",
        "    if len(tokens_bert) > maior_chunk_token_bert:\n",
        "      maior_chunk_token_bert = len(tokens_bert)\n",
        "    if len(chunk.page_content) > maior_chunk_character:\n",
        "      maior_chunk_character = len(chunk.page_content)\n",
        "\n",
        "print(\"Maior chunk token:\", maior_chunk_token)\n",
        "print(\"Maior chunk token bert:\", maior_chunk_token_bert)\n",
        "print(\"Maior chunk character:\", maior_chunk_character)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVyaTCP3vJbR",
        "outputId": "54ff5be6-5438-494b-9e99-0613cf24ba4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk # 0  qtde char : 217  qtde token : 25  qtde token bert: 50\n",
            "chunk # 1  qtde char : 1922  qtde token : 308  qtde token bert: 497\n",
            "chunk # 2  qtde char : 1956  qtde token : 316  qtde token bert: 494\n",
            "chunk # 3  qtde char : 1972  qtde token : 301  qtde token bert: 495\n",
            "chunk # 4  qtde char : 1907  qtde token : 299  qtde token bert: 483\n",
            "chunk # 5  qtde char : 1907  qtde token : 297  qtde token bert: 492\n",
            "chunk # 6  qtde char : 1873  qtde token : 283  qtde token bert: 490\n",
            "chunk # 7  qtde char : 1934  qtde token : 302  qtde token bert: 481\n",
            "chunk # 8  qtde char : 1915  qtde token : 298  qtde token bert: 491\n",
            "chunk # 9  qtde char : 2139  qtde token : 321  qtde token bert: 500\n",
            "chunk # 10  qtde char : 2048  qtde token : 312  qtde token bert: 491\n",
            "chunk # 11  qtde char : 2072  qtde token : 317  qtde token bert: 500\n",
            "chunk # 12  qtde char : 2073  qtde token : 318  qtde token bert: 497\n",
            "chunk # 13  qtde char : 1936  qtde token : 290  qtde token bert: 499\n",
            "chunk # 14  qtde char : 2009  qtde token : 290  qtde token bert: 491\n",
            "chunk # 15  qtde char : 1992  qtde token : 283  qtde token bert: 500\n",
            "chunk # 16  qtde char : 1870  qtde token : 281  qtde token bert: 491\n",
            "chunk # 17  qtde char : 1827  qtde token : 281  qtde token bert: 483\n",
            "chunk # 18  qtde char : 1871  qtde token : 291  qtde token bert: 498\n",
            "chunk # 19  qtde char : 1870  qtde token : 285  qtde token bert: 500\n",
            "chunk # 20  qtde char : 1705  qtde token : 278  qtde token bert: 496\n",
            "chunk # 21  qtde char : 1935  qtde token : 283  qtde token bert: 495\n",
            "chunk # 22  qtde char : 2043  qtde token : 311  qtde token bert: 495\n",
            "chunk # 23  qtde char : 2083  qtde token : 300  qtde token bert: 499\n",
            "chunk # 24  qtde char : 1954  qtde token : 298  qtde token bert: 497\n",
            "chunk # 25  qtde char : 1931  qtde token : 296  qtde token bert: 485\n",
            "chunk # 26  qtde char : 1916  qtde token : 300  qtde token bert: 482\n",
            "chunk # 27  qtde char : 1850  qtde token : 297  qtde token bert: 497\n",
            "chunk # 28  qtde char : 2008  qtde token : 327  qtde token bert: 493\n",
            "chunk # 29  qtde char : 2065  qtde token : 320  qtde token bert: 500\n",
            "chunk # 30  qtde char : 1968  qtde token : 295  qtde token bert: 490\n",
            "chunk # 31  qtde char : 2044  qtde token : 309  qtde token bert: 488\n",
            "chunk # 32  qtde char : 1957  qtde token : 284  qtde token bert: 499\n",
            "chunk # 33  qtde char : 2001  qtde token : 296  qtde token bert: 496\n",
            "chunk # 34  qtde char : 2012  qtde token : 307  qtde token bert: 496\n",
            "chunk # 35  qtde char : 1753  qtde token : 283  qtde token bert: 493\n",
            "chunk # 36  qtde char : 1742  qtde token : 272  qtde token bert: 495\n",
            "chunk # 37  qtde char : 1781  qtde token : 261  qtde token bert: 491\n",
            "chunk # 38  qtde char : 2045  qtde token : 304  qtde token bert: 497\n",
            "chunk # 39  qtde char : 1946  qtde token : 293  qtde token bert: 490\n",
            "chunk # 40  qtde char : 2047  qtde token : 330  qtde token bert: 499\n",
            "chunk # 41  qtde char : 1978  qtde token : 323  qtde token bert: 494\n",
            "chunk # 42  qtde char : 2011  qtde token : 299  qtde token bert: 498\n",
            "chunk # 43  qtde char : 1926  qtde token : 302  qtde token bert: 491\n",
            "chunk # 44  qtde char : 1990  qtde token : 311  qtde token bert: 497\n",
            "chunk # 45  qtde char : 1952  qtde token : 305  qtde token bert: 500\n",
            "chunk # 46  qtde char : 1879  qtde token : 309  qtde token bert: 486\n",
            "chunk # 47  qtde char : 1966  qtde token : 309  qtde token bert: 500\n",
            "chunk # 48  qtde char : 1805  qtde token : 290  qtde token bert: 491\n",
            "chunk # 49  qtde char : 2099  qtde token : 323  qtde token bert: 499\n",
            "chunk # 50  qtde char : 1991  qtde token : 304  qtde token bert: 500\n",
            "chunk # 51  qtde char : 1849  qtde token : 273  qtde token bert: 497\n",
            "chunk # 52  qtde char : 1791  qtde token : 275  qtde token bert: 484\n",
            "chunk # 53  qtde char : 1889  qtde token : 283  qtde token bert: 497\n",
            "chunk # 54  qtde char : 1931  qtde token : 275  qtde token bert: 500\n",
            "chunk # 55  qtde char : 1971  qtde token : 303  qtde token bert: 496\n",
            "chunk # 56  qtde char : 1862  qtde token : 271  qtde token bert: 488\n",
            "chunk # 57  qtde char : 1853  qtde token : 262  qtde token bert: 496\n",
            "chunk # 58  qtde char : 1791  qtde token : 260  qtde token bert: 496\n",
            "chunk # 59  qtde char : 1971  qtde token : 303  qtde token bert: 488\n",
            "chunk # 60  qtde char : 2046  qtde token : 311  qtde token bert: 496\n",
            "chunk # 61  qtde char : 2001  qtde token : 301  qtde token bert: 498\n",
            "chunk # 62  qtde char : 1850  qtde token : 288  qtde token bert: 492\n",
            "chunk # 63  qtde char : 2006  qtde token : 318  qtde token bert: 498\n",
            "chunk # 64  qtde char : 2200  qtde token : 333  qtde token bert: 494\n",
            "chunk # 65  qtde char : 1992  qtde token : 304  qtde token bert: 497\n",
            "chunk # 66  qtde char : 1931  qtde token : 292  qtde token bert: 500\n",
            "chunk # 67  qtde char : 1803  qtde token : 274  qtde token bert: 487\n",
            "chunk # 68  qtde char : 1990  qtde token : 307  qtde token bert: 500\n",
            "chunk # 69  qtde char : 843  qtde token : 119  qtde token bert: 220\n",
            "chunk # 70  qtde char : 1826  qtde token : 283  qtde token bert: 492\n",
            "chunk # 71  qtde char : 2038  qtde token : 307  qtde token bert: 497\n",
            "chunk # 72  qtde char : 2091  qtde token : 307  qtde token bert: 498\n",
            "chunk # 73  qtde char : 2034  qtde token : 283  qtde token bert: 496\n",
            "chunk # 74  qtde char : 1879  qtde token : 291  qtde token bert: 489\n",
            "chunk # 75  qtde char : 1845  qtde token : 277  qtde token bert: 492\n",
            "chunk # 76  qtde char : 2032  qtde token : 300  qtde token bert: 497\n",
            "chunk # 77  qtde char : 2006  qtde token : 303  qtde token bert: 496\n",
            "chunk # 78  qtde char : 2004  qtde token : 294  qtde token bert: 500\n",
            "chunk # 79  qtde char : 1896  qtde token : 293  qtde token bert: 479\n",
            "chunk # 80  qtde char : 2094  qtde token : 325  qtde token bert: 496\n",
            "chunk # 81  qtde char : 2212  qtde token : 349  qtde token bert: 498\n",
            "chunk # 82  qtde char : 1955  qtde token : 303  qtde token bert: 494\n",
            "chunk # 83  qtde char : 2010  qtde token : 294  qtde token bert: 497\n",
            "chunk # 84  qtde char : 1974  qtde token : 290  qtde token bert: 485\n",
            "chunk # 85  qtde char : 2000  qtde token : 290  qtde token bert: 492\n",
            "chunk # 86  qtde char : 1953  qtde token : 279  qtde token bert: 493\n",
            "chunk # 87  qtde char : 1695  qtde token : 263  qtde token bert: 408\n",
            "chunk # 88  qtde char : 1959  qtde token : 283  qtde token bert: 496\n",
            "chunk # 89  qtde char : 1946  qtde token : 272  qtde token bert: 493\n",
            "chunk # 90  qtde char : 1881  qtde token : 275  qtde token bert: 482\n",
            "chunk # 91  qtde char : 1847  qtde token : 279  qtde token bert: 499\n",
            "chunk # 92  qtde char : 1863  qtde token : 283  qtde token bert: 482\n",
            "chunk # 93  qtde char : 1971  qtde token : 292  qtde token bert: 494\n",
            "chunk # 94  qtde char : 1839  qtde token : 265  qtde token bert: 484\n",
            "chunk # 95  qtde char : 1823  qtde token : 264  qtde token bert: 490\n",
            "chunk # 96  qtde char : 1930  qtde token : 290  qtde token bert: 497\n",
            "chunk # 97  qtde char : 2133  qtde token : 294  qtde token bert: 496\n",
            "chunk # 98  qtde char : 2091  qtde token : 301  qtde token bert: 500\n",
            "chunk # 99  qtde char : 1906  qtde token : 293  qtde token bert: 484\n",
            "chunk # 100  qtde char : 1875  qtde token : 282  qtde token bert: 488\n",
            "chunk # 101  qtde char : 1560  qtde token : 238  qtde token bert: 481\n",
            "chunk # 102  qtde char : 1717  qtde token : 258  qtde token bert: 497\n",
            "chunk # 103  qtde char : 1946  qtde token : 288  qtde token bert: 500\n",
            "chunk # 104  qtde char : 1805  qtde token : 272  qtde token bert: 484\n",
            "chunk # 105  qtde char : 1755  qtde token : 276  qtde token bert: 487\n",
            "chunk # 106  qtde char : 1680  qtde token : 262  qtde token bert: 484\n",
            "chunk # 107  qtde char : 1971  qtde token : 294  qtde token bert: 492\n",
            "chunk # 108  qtde char : 1953  qtde token : 298  qtde token bert: 493\n",
            "chunk # 109  qtde char : 2001  qtde token : 292  qtde token bert: 493\n",
            "chunk # 110  qtde char : 2071  qtde token : 326  qtde token bert: 498\n",
            "chunk # 111  qtde char : 2040  qtde token : 294  qtde token bert: 494\n",
            "chunk # 112  qtde char : 1909  qtde token : 273  qtde token bert: 489\n",
            "chunk # 113  qtde char : 1901  qtde token : 288  qtde token bert: 491\n",
            "chunk # 114  qtde char : 1840  qtde token : 282  qtde token bert: 496\n",
            "chunk # 115  qtde char : 2000  qtde token : 309  qtde token bert: 496\n",
            "chunk # 116  qtde char : 2001  qtde token : 304  qtde token bert: 485\n",
            "chunk # 117  qtde char : 2076  qtde token : 319  qtde token bert: 487\n",
            "chunk # 118  qtde char : 1969  qtde token : 277  qtde token bert: 495\n",
            "chunk # 119  qtde char : 1966  qtde token : 293  qtde token bert: 476\n",
            "chunk # 120  qtde char : 2041  qtde token : 298  qtde token bert: 500\n",
            "chunk # 121  qtde char : 1905  qtde token : 267  qtde token bert: 497\n",
            "chunk # 122  qtde char : 1846  qtde token : 292  qtde token bert: 492\n",
            "chunk # 123  qtde char : 1578  qtde token : 268  qtde token bert: 481\n",
            "chunk # 124  qtde char : 1881  qtde token : 297  qtde token bert: 490\n",
            "chunk # 125  qtde char : 1787  qtde token : 288  qtde token bert: 500\n",
            "chunk # 126  qtde char : 1672  qtde token : 275  qtde token bert: 490\n",
            "chunk # 127  qtde char : 1799  qtde token : 293  qtde token bert: 481\n",
            "chunk # 128  qtde char : 1813  qtde token : 289  qtde token bert: 490\n",
            "chunk # 129  qtde char : 1897  qtde token : 290  qtde token bert: 493\n",
            "chunk # 130  qtde char : 2083  qtde token : 322  qtde token bert: 487\n",
            "chunk # 131  qtde char : 1993  qtde token : 310  qtde token bert: 500\n",
            "chunk # 132  qtde char : 1952  qtde token : 314  qtde token bert: 499\n",
            "chunk # 133  qtde char : 2090  qtde token : 295  qtde token bert: 498\n",
            "chunk # 134  qtde char : 1930  qtde token : 275  qtde token bert: 500\n",
            "chunk # 135  qtde char : 1929  qtde token : 283  qtde token bert: 491\n",
            "chunk # 136  qtde char : 2251  qtde token : 308  qtde token bert: 500\n",
            "chunk # 137  qtde char : 1891  qtde token : 278  qtde token bert: 486\n",
            "chunk # 138  qtde char : 1771  qtde token : 276  qtde token bert: 497\n",
            "chunk # 139  qtde char : 1886  qtde token : 295  qtde token bert: 493\n",
            "chunk # 140  qtde char : 1764  qtde token : 273  qtde token bert: 483\n",
            "chunk # 141  qtde char : 1633  qtde token : 267  qtde token bert: 489\n",
            "chunk # 142  qtde char : 1698  qtde token : 267  qtde token bert: 485\n",
            "chunk # 143  qtde char : 2007  qtde token : 301  qtde token bert: 482\n",
            "chunk # 144  qtde char : 2039  qtde token : 310  qtde token bert: 491\n",
            "chunk # 145  qtde char : 2041  qtde token : 302  qtde token bert: 499\n",
            "chunk # 146  qtde char : 1815  qtde token : 271  qtde token bert: 500\n",
            "chunk # 147  qtde char : 1757  qtde token : 280  qtde token bert: 497\n",
            "chunk # 148  qtde char : 1745  qtde token : 265  qtde token bert: 489\n",
            "chunk # 149  qtde char : 1962  qtde token : 294  qtde token bert: 495\n",
            "chunk # 150  qtde char : 1927  qtde token : 291  qtde token bert: 483\n",
            "chunk # 151  qtde char : 2005  qtde token : 291  qtde token bert: 493\n",
            "chunk # 152  qtde char : 1970  qtde token : 286  qtde token bert: 490\n",
            "chunk # 153  qtde char : 1981  qtde token : 299  qtde token bert: 494\n",
            "chunk # 154  qtde char : 1843  qtde token : 298  qtde token bert: 486\n",
            "chunk # 155  qtde char : 1976  qtde token : 290  qtde token bert: 497\n",
            "chunk # 156  qtde char : 1935  qtde token : 286  qtde token bert: 491\n",
            "chunk # 157  qtde char : 1877  qtde token : 309  qtde token bert: 498\n",
            "chunk # 158  qtde char : 1705  qtde token : 270  qtde token bert: 490\n",
            "chunk # 159  qtde char : 1815  qtde token : 279  qtde token bert: 495\n",
            "chunk # 160  qtde char : 1944  qtde token : 289  qtde token bert: 494\n",
            "chunk # 161  qtde char : 1857  qtde token : 282  qtde token bert: 494\n",
            "chunk # 162  qtde char : 1656  qtde token : 271  qtde token bert: 498\n",
            "chunk # 163  qtde char : 1889  qtde token : 293  qtde token bert: 491\n",
            "chunk # 164  qtde char : 1785  qtde token : 279  qtde token bert: 496\n",
            "chunk # 165  qtde char : 1879  qtde token : 284  qtde token bert: 496\n",
            "chunk # 166  qtde char : 1756  qtde token : 266  qtde token bert: 500\n",
            "chunk # 167  qtde char : 1772  qtde token : 274  qtde token bert: 495\n",
            "chunk # 168  qtde char : 1825  qtde token : 285  qtde token bert: 491\n",
            "chunk # 169  qtde char : 1878  qtde token : 304  qtde token bert: 496\n",
            "chunk # 170  qtde char : 1878  qtde token : 278  qtde token bert: 497\n",
            "chunk # 171  qtde char : 1950  qtde token : 281  qtde token bert: 489\n",
            "chunk # 172  qtde char : 2167  qtde token : 317  qtde token bert: 486\n",
            "chunk # 173  qtde char : 1915  qtde token : 300  qtde token bert: 494\n",
            "chunk # 174  qtde char : 1929  qtde token : 295  qtde token bert: 492\n",
            "chunk # 175  qtde char : 1752  qtde token : 274  qtde token bert: 497\n",
            "chunk # 176  qtde char : 1991  qtde token : 312  qtde token bert: 491\n",
            "chunk # 177  qtde char : 2047  qtde token : 324  qtde token bert: 484\n",
            "chunk # 178  qtde char : 1892  qtde token : 297  qtde token bert: 493\n",
            "chunk # 179  qtde char : 2124  qtde token : 330  qtde token bert: 494\n",
            "chunk # 180  qtde char : 2223  qtde token : 331  qtde token bert: 499\n",
            "chunk # 181  qtde char : 2042  qtde token : 318  qtde token bert: 495\n",
            "chunk # 182  qtde char : 1937  qtde token : 292  qtde token bert: 488\n",
            "chunk # 183  qtde char : 1940  qtde token : 290  qtde token bert: 490\n",
            "chunk # 184  qtde char : 1867  qtde token : 296  qtde token bert: 493\n",
            "chunk # 185  qtde char : 1896  qtde token : 306  qtde token bert: 493\n",
            "chunk # 186  qtde char : 1928  qtde token : 309  qtde token bert: 485\n",
            "chunk # 187  qtde char : 2063  qtde token : 306  qtde token bert: 493\n",
            "chunk # 188  qtde char : 2035  qtde token : 312  qtde token bert: 485\n",
            "chunk # 189  qtde char : 1903  qtde token : 293  qtde token bert: 495\n",
            "chunk # 190  qtde char : 1796  qtde token : 274  qtde token bert: 492\n",
            "chunk # 191  qtde char : 1852  qtde token : 282  qtde token bert: 498\n",
            "chunk # 192  qtde char : 1985  qtde token : 296  qtde token bert: 492\n",
            "chunk # 193  qtde char : 2035  qtde token : 309  qtde token bert: 494\n",
            "chunk # 194  qtde char : 1779  qtde token : 300  qtde token bert: 500\n",
            "chunk # 195  qtde char : 1916  qtde token : 286  qtde token bert: 497\n",
            "chunk # 196  qtde char : 1846  qtde token : 297  qtde token bert: 495\n",
            "chunk # 197  qtde char : 1846  qtde token : 274  qtde token bert: 497\n",
            "chunk # 198  qtde char : 1754  qtde token : 268  qtde token bert: 491\n",
            "chunk # 199  qtde char : 1905  qtde token : 287  qtde token bert: 494\n",
            "chunk # 200  qtde char : 2042  qtde token : 295  qtde token bert: 500\n",
            "chunk # 201  qtde char : 1646  qtde token : 253  qtde token bert: 487\n",
            "chunk # 202  qtde char : 1820  qtde token : 294  qtde token bert: 498\n",
            "chunk # 203  qtde char : 2063  qtde token : 320  qtde token bert: 498\n",
            "chunk # 204  qtde char : 2031  qtde token : 313  qtde token bert: 497\n",
            "chunk # 205  qtde char : 1814  qtde token : 283  qtde token bert: 495\n",
            "chunk # 206  qtde char : 1812  qtde token : 298  qtde token bert: 499\n",
            "chunk # 207  qtde char : 1965  qtde token : 299  qtde token bert: 499\n",
            "chunk # 208  qtde char : 2018  qtde token : 316  qtde token bert: 498\n",
            "chunk # 209  qtde char : 1895  qtde token : 285  qtde token bert: 492\n",
            "chunk # 210  qtde char : 1787  qtde token : 288  qtde token bert: 487\n",
            "chunk # 211  qtde char : 2010  qtde token : 302  qtde token bert: 499\n",
            "chunk # 212  qtde char : 1975  qtde token : 282  qtde token bert: 497\n",
            "chunk # 213  qtde char : 1724  qtde token : 267  qtde token bert: 482\n",
            "chunk # 214  qtde char : 1884  qtde token : 286  qtde token bert: 496\n",
            "chunk # 215  qtde char : 1978  qtde token : 287  qtde token bert: 493\n",
            "chunk # 216  qtde char : 2013  qtde token : 296  qtde token bert: 498\n",
            "chunk # 217  qtde char : 1978  qtde token : 322  qtde token bert: 492\n",
            "chunk # 218  qtde char : 1928  qtde token : 279  qtde token bert: 491\n",
            "chunk # 219  qtde char : 1917  qtde token : 288  qtde token bert: 498\n",
            "chunk # 220  qtde char : 1936  qtde token : 293  qtde token bert: 494\n",
            "chunk # 221  qtde char : 2194  qtde token : 317  qtde token bert: 493\n",
            "chunk # 222  qtde char : 2144  qtde token : 326  qtde token bert: 499\n",
            "chunk # 223  qtde char : 2019  qtde token : 306  qtde token bert: 491\n",
            "chunk # 224  qtde char : 1972  qtde token : 295  qtde token bert: 492\n",
            "chunk # 225  qtde char : 1893  qtde token : 273  qtde token bert: 489\n",
            "chunk # 226  qtde char : 1931  qtde token : 281  qtde token bert: 499\n",
            "chunk # 227  qtde char : 2037  qtde token : 303  qtde token bert: 495\n",
            "chunk # 228  qtde char : 1945  qtde token : 296  qtde token bert: 489\n",
            "chunk # 229  qtde char : 1959  qtde token : 304  qtde token bert: 499\n",
            "chunk # 230  qtde char : 1919  qtde token : 294  qtde token bert: 496\n",
            "chunk # 231  qtde char : 1856  qtde token : 292  qtde token bert: 495\n",
            "chunk # 232  qtde char : 1887  qtde token : 286  qtde token bert: 491\n",
            "chunk # 233  qtde char : 1889  qtde token : 284  qtde token bert: 490\n",
            "chunk # 234  qtde char : 1764  qtde token : 269  qtde token bert: 497\n",
            "chunk # 235  qtde char : 2057  qtde token : 317  qtde token bert: 495\n",
            "chunk # 236  qtde char : 2081  qtde token : 307  qtde token bert: 487\n",
            "chunk # 237  qtde char : 2121  qtde token : 310  qtde token bert: 493\n",
            "chunk # 238  qtde char : 2007  qtde token : 288  qtde token bert: 497\n",
            "chunk # 239  qtde char : 1933  qtde token : 279  qtde token bert: 493\n",
            "chunk # 240  qtde char : 1820  qtde token : 280  qtde token bert: 496\n",
            "chunk # 241  qtde char : 1815  qtde token : 284  qtde token bert: 483\n",
            "chunk # 242  qtde char : 1849  qtde token : 275  qtde token bert: 497\n",
            "chunk # 243  qtde char : 1984  qtde token : 288  qtde token bert: 494\n",
            "chunk # 244  qtde char : 1923  qtde token : 277  qtde token bert: 496\n",
            "chunk # 245  qtde char : 2016  qtde token : 294  qtde token bert: 493\n",
            "chunk # 246  qtde char : 2065  qtde token : 305  qtde token bert: 495\n",
            "chunk # 247  qtde char : 2012  qtde token : 294  qtde token bert: 499\n",
            "chunk # 248  qtde char : 1817  qtde token : 263  qtde token bert: 487\n",
            "chunk # 249  qtde char : 1930  qtde token : 308  qtde token bert: 490\n",
            "chunk # 250  qtde char : 1973  qtde token : 306  qtde token bert: 495\n",
            "chunk # 251  qtde char : 2035  qtde token : 310  qtde token bert: 500\n",
            "chunk # 252  qtde char : 2019  qtde token : 305  qtde token bert: 497\n",
            "chunk # 253  qtde char : 2037  qtde token : 304  qtde token bert: 492\n",
            "chunk # 254  qtde char : 1372  qtde token : 208  qtde token bert: 357\n",
            "chunk # 255  qtde char : 1772  qtde token : 276  qtde token bert: 500\n",
            "chunk # 256  qtde char : 1943  qtde token : 302  qtde token bert: 496\n",
            "chunk # 257  qtde char : 1950  qtde token : 288  qtde token bert: 497\n",
            "chunk # 258  qtde char : 1695  qtde token : 267  qtde token bert: 492\n",
            "chunk # 259  qtde char : 1915  qtde token : 281  qtde token bert: 497\n",
            "chunk # 260  qtde char : 2121  qtde token : 315  qtde token bert: 499\n",
            "chunk # 261  qtde char : 1816  qtde token : 290  qtde token bert: 477\n",
            "chunk # 262  qtde char : 1860  qtde token : 268  qtde token bert: 495\n",
            "chunk # 263  qtde char : 1981  qtde token : 289  qtde token bert: 498\n",
            "chunk # 264  qtde char : 1809  qtde token : 279  qtde token bert: 475\n",
            "chunk # 265  qtde char : 1650  qtde token : 275  qtde token bert: 487\n",
            "chunk # 266  qtde char : 1851  qtde token : 291  qtde token bert: 498\n",
            "chunk # 267  qtde char : 1988  qtde token : 295  qtde token bert: 479\n",
            "chunk # 268  qtde char : 1819  qtde token : 275  qtde token bert: 482\n",
            "chunk # 269  qtde char : 1734  qtde token : 268  qtde token bert: 483\n",
            "chunk # 270  qtde char : 1907  qtde token : 291  qtde token bert: 487\n",
            "chunk # 271  qtde char : 1896  qtde token : 280  qtde token bert: 495\n",
            "chunk # 272  qtde char : 1950  qtde token : 301  qtde token bert: 489\n",
            "chunk # 273  qtde char : 2114  qtde token : 319  qtde token bert: 499\n",
            "chunk # 274  qtde char : 2067  qtde token : 289  qtde token bert: 499\n",
            "chunk # 275  qtde char : 1961  qtde token : 281  qtde token bert: 494\n",
            "chunk # 276  qtde char : 1837  qtde token : 263  qtde token bert: 492\n",
            "chunk # 277  qtde char : 1781  qtde token : 265  qtde token bert: 483\n",
            "chunk # 278  qtde char : 1765  qtde token : 280  qtde token bert: 489\n",
            "chunk # 279  qtde char : 1761  qtde token : 269  qtde token bert: 492\n",
            "chunk # 280  qtde char : 1797  qtde token : 281  qtde token bert: 490\n",
            "chunk # 281  qtde char : 2010  qtde token : 307  qtde token bert: 499\n",
            "chunk # 282  qtde char : 1897  qtde token : 278  qtde token bert: 489\n",
            "chunk # 283  qtde char : 1808  qtde token : 267  qtde token bert: 493\n",
            "chunk # 284  qtde char : 1457  qtde token : 188  qtde token bert: 488\n",
            "chunk # 285  qtde char : 2030  qtde token : 282  qtde token bert: 489\n",
            "chunk # 286  qtde char : 1903  qtde token : 273  qtde token bert: 500\n",
            "chunk # 287  qtde char : 1669  qtde token : 265  qtde token bert: 490\n",
            "chunk # 288  qtde char : 1515  qtde token : 247  qtde token bert: 482\n",
            "chunk # 289  qtde char : 1676  qtde token : 270  qtde token bert: 498\n",
            "chunk # 290  qtde char : 1840  qtde token : 279  qtde token bert: 498\n",
            "chunk # 291  qtde char : 1930  qtde token : 287  qtde token bert: 486\n",
            "chunk # 292  qtde char : 1829  qtde token : 272  qtde token bert: 492\n",
            "chunk # 293  qtde char : 1987  qtde token : 302  qtde token bert: 497\n",
            "chunk # 294  qtde char : 1985  qtde token : 284  qtde token bert: 495\n",
            "chunk # 295  qtde char : 1875  qtde token : 291  qtde token bert: 497\n",
            "chunk # 296  qtde char : 1713  qtde token : 268  qtde token bert: 499\n",
            "chunk # 297  qtde char : 1881  qtde token : 267  qtde token bert: 486\n",
            "chunk # 298  qtde char : 1923  qtde token : 284  qtde token bert: 481\n",
            "chunk # 299  qtde char : 1837  qtde token : 274  qtde token bert: 494\n",
            "chunk # 300  qtde char : 1933  qtde token : 285  qtde token bert: 495\n",
            "chunk # 301  qtde char : 1945  qtde token : 281  qtde token bert: 490\n",
            "chunk # 302  qtde char : 1874  qtde token : 282  qtde token bert: 497\n",
            "chunk # 303  qtde char : 1803  qtde token : 256  qtde token bert: 487\n",
            "chunk # 304  qtde char : 1931  qtde token : 280  qtde token bert: 495\n",
            "chunk # 305  qtde char : 1962  qtde token : 268  qtde token bert: 491\n",
            "chunk # 306  qtde char : 1840  qtde token : 272  qtde token bert: 493\n",
            "chunk # 307  qtde char : 2008  qtde token : 296  qtde token bert: 499\n",
            "chunk # 308  qtde char : 1722  qtde token : 245  qtde token bert: 486\n",
            "chunk # 309  qtde char : 1851  qtde token : 284  qtde token bert: 487\n",
            "chunk # 310  qtde char : 1795  qtde token : 279  qtde token bert: 495\n",
            "chunk # 311  qtde char : 1795  qtde token : 267  qtde token bert: 500\n",
            "chunk # 312  qtde char : 1794  qtde token : 275  qtde token bert: 482\n",
            "chunk # 313  qtde char : 1945  qtde token : 281  qtde token bert: 499\n",
            "chunk # 314  qtde char : 1849  qtde token : 270  qtde token bert: 487\n",
            "chunk # 315  qtde char : 1964  qtde token : 293  qtde token bert: 497\n",
            "chunk # 316  qtde char : 1953  qtde token : 288  qtde token bert: 493\n",
            "chunk # 317  qtde char : 1711  qtde token : 253  qtde token bert: 500\n",
            "chunk # 318  qtde char : 1727  qtde token : 257  qtde token bert: 498\n",
            "chunk # 319  qtde char : 1700  qtde token : 258  qtde token bert: 492\n",
            "chunk # 320  qtde char : 1743  qtde token : 247  qtde token bert: 492\n",
            "chunk # 321  qtde char : 1752  qtde token : 281  qtde token bert: 490\n",
            "chunk # 322  qtde char : 1866  qtde token : 280  qtde token bert: 484\n",
            "chunk # 323  qtde char : 1977  qtde token : 300  qtde token bert: 494\n",
            "chunk # 324  qtde char : 1770  qtde token : 263  qtde token bert: 485\n",
            "chunk # 325  qtde char : 1869  qtde token : 288  qtde token bert: 498\n",
            "chunk # 326  qtde char : 2001  qtde token : 304  qtde token bert: 484\n",
            "chunk # 327  qtde char : 2087  qtde token : 312  qtde token bert: 489\n",
            "chunk # 328  qtde char : 1858  qtde token : 275  qtde token bert: 491\n",
            "chunk # 329  qtde char : 1753  qtde token : 249  qtde token bert: 488\n",
            "chunk # 330  qtde char : 1766  qtde token : 270  qtde token bert: 492\n",
            "chunk # 331  qtde char : 1708  qtde token : 255  qtde token bert: 494\n",
            "chunk # 332  qtde char : 2030  qtde token : 314  qtde token bert: 496\n",
            "chunk # 333  qtde char : 1871  qtde token : 291  qtde token bert: 484\n",
            "chunk # 334  qtde char : 1904  qtde token : 278  qtde token bert: 500\n",
            "chunk # 335  qtde char : 1901  qtde token : 287  qtde token bert: 494\n",
            "chunk # 336  qtde char : 1904  qtde token : 274  qtde token bert: 498\n",
            "chunk # 337  qtde char : 1824  qtde token : 272  qtde token bert: 493\n",
            "chunk # 338  qtde char : 1940  qtde token : 290  qtde token bert: 494\n",
            "chunk # 339  qtde char : 1985  qtde token : 294  qtde token bert: 491\n",
            "chunk # 340  qtde char : 1602  qtde token : 241  qtde token bert: 497\n",
            "chunk # 341  qtde char : 1786  qtde token : 279  qtde token bert: 487\n",
            "chunk # 342  qtde char : 1703  qtde token : 253  qtde token bert: 500\n",
            "chunk # 343  qtde char : 1819  qtde token : 278  qtde token bert: 491\n",
            "chunk # 344  qtde char : 1965  qtde token : 283  qtde token bert: 494\n",
            "chunk # 345  qtde char : 1850  qtde token : 280  qtde token bert: 500\n",
            "chunk # 346  qtde char : 1466  qtde token : 217  qtde token bert: 489\n",
            "chunk # 347  qtde char : 1709  qtde token : 254  qtde token bert: 486\n",
            "chunk # 348  qtde char : 1927  qtde token : 280  qtde token bert: 485\n",
            "chunk # 349  qtde char : 2020  qtde token : 301  qtde token bert: 494\n",
            "chunk # 350  qtde char : 2032  qtde token : 308  qtde token bert: 493\n",
            "chunk # 351  qtde char : 1800  qtde token : 275  qtde token bert: 491\n",
            "chunk # 352  qtde char : 1800  qtde token : 284  qtde token bert: 493\n",
            "chunk # 353  qtde char : 2075  qtde token : 314  qtde token bert: 496\n",
            "chunk # 354  qtde char : 1898  qtde token : 303  qtde token bert: 500\n",
            "chunk # 355  qtde char : 1884  qtde token : 265  qtde token bert: 488\n",
            "chunk # 356  qtde char : 2036  qtde token : 306  qtde token bert: 500\n",
            "chunk # 357  qtde char : 1731  qtde token : 263  qtde token bert: 500\n",
            "chunk # 358  qtde char : 1697  qtde token : 257  qtde token bert: 494\n",
            "chunk # 359  qtde char : 1659  qtde token : 247  qtde token bert: 488\n",
            "chunk # 360  qtde char : 2079  qtde token : 307  qtde token bert: 499\n",
            "chunk # 361  qtde char : 1948  qtde token : 283  qtde token bert: 484\n",
            "chunk # 362  qtde char : 1859  qtde token : 278  qtde token bert: 490\n",
            "chunk # 363  qtde char : 1952  qtde token : 285  qtde token bert: 497\n",
            "chunk # 364  qtde char : 1727  qtde token : 243  qtde token bert: 496\n",
            "chunk # 365  qtde char : 1630  qtde token : 242  qtde token bert: 492\n",
            "chunk # 366  qtde char : 1783  qtde token : 279  qtde token bert: 489\n",
            "chunk # 367  qtde char : 1773  qtde token : 266  qtde token bert: 489\n",
            "chunk # 368  qtde char : 1800  qtde token : 263  qtde token bert: 484\n",
            "chunk # 369  qtde char : 1966  qtde token : 282  qtde token bert: 484\n",
            "chunk # 370  qtde char : 1973  qtde token : 285  qtde token bert: 490\n",
            "chunk # 371  qtde char : 1660  qtde token : 246  qtde token bert: 498\n",
            "chunk # 372  qtde char : 1792  qtde token : 270  qtde token bert: 493\n",
            "chunk # 373  qtde char : 1848  qtde token : 270  qtde token bert: 495\n",
            "chunk # 374  qtde char : 1255  qtde token : 176  qtde token bert: 346\n",
            "Maior chunk token: 349\n",
            "Maior chunk token bert: 500\n",
            "Maior chunk character: 2251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 - Armazena os chunks\n",
        "\n",
        "Utiliza o Chroma um banco de dados de embeddings de código aberto e leve.\n",
        "\n",
        "https://www.trychroma.com/\n",
        "\n",
        "https://heidloff.net/article/retrieval-augmented-generation-chroma-langchain/"
      ],
      "metadata": {
        "id": "cLSk7vNBWMla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Armazena os chunks usando o Chroma\n",
        "vectorstore = Chroma.from_documents(documents=chunks, embedding=model_lm, persist_directory=\"./bancodedados\", )"
      ],
      "metadata": {
        "id": "rsXZLkeCWPIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epsEHDsGQJAC"
      },
      "source": [
        "## 3.4 - Função de envio de perguntas ao LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import PromptTemplate\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "def avaliarContexto(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Você é um assistente de IA útil e fornece a resposta para a pergunta com base no contexto fornecido.\n",
        "Contexto: {context}\n",
        ">>PERGUNTA<< {question}\n",
        ">>RESPOSTA<<\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  # As variáveis \"context\" e \"question\" não podem ser alteradas\n",
        "  # O parâmetro \"context\" recebe o contexto do carregado e armazenado no Chroma\n",
        "  # O parâmetro \"question\" recebe a pergunta realizada sobre o contexto.\n",
        "  prompt = PromptTemplate(input_variables=[\"context\", \"question\"],\n",
        "                          template=prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain_type_kwargs = {\"prompt\": prompt}\n",
        "  chain = RetrievalQA.from_chain_type(\n",
        "        llm=model_llm,\n",
        "        chain_type=\"stuff\",\n",
        "        #retriever=vectorstore.as_retriever(), # Passa o contexto(livro carregado)\n",
        "        retriever=vectorstore.as_retriever(search_kwargs={'k':1}),\n",
        "        chain_type_kwargs=chain_type_kwargs\n",
        "    )\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.run(texto)\n",
        "\n",
        "  # Esvazia a memória\n",
        "  del chain\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return resultado"
      ],
      "metadata": {
        "id": "ToMVt5GkkqEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 - Algumas perguntas usando o contexto"
      ],
      "metadata": {
        "id": "l_iS635Fftog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guarda o tempo de início de realização das perguntas"
      ],
      "metadata": {
        "id": "GYZeuWBf6AV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()"
      ],
      "metadata": {
        "id": "qxGyZ-El6DK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCeR9lv5_Fxd",
        "outputId": "d2a42127-bfff-4710-a31e-a1917812f889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O período que ocorre na história do texto é o século XIX.\n"
          ]
        }
      ],
      "source": [
        "texto = \"Qual o período que ocorre a história do texto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto em qual período que ocorre os fatos?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBbhBnY3ul45",
        "outputId": "7455b4fa-98eb-40e6-e6b8-c88f90d5d4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O contexto é o século XIX, no Brasil, durante a época da escravidão.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Qual o nome de todos os personagens do contexto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn3S9FO4zYRd",
        "outputId": "b83b34c0-2039-4b1b-dbfc-6fe07c59dd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Simeão, o Barbudo, Eufêmia e outros cúmplices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto qual o nome de todos os personagens da história?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK-_KNVozeoO",
        "outputId": "6e45b290-b463-46b5-fb0c-e1289cc44486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os personagens da história são:\n",
            "\n",
            "1. Simeão\n",
            "2. Eufêmia\n",
            "3. o Barbudo\n",
            "4. os cúmplices (não especificados)\n",
            "\n",
            "Portanto, o nom\n",
            "e de todos os personagens da história é:\n",
            "\n",
            "1. Simeão\n",
            "2. Eufêmia\n",
            "3. o Barbudo\n",
            "4. os cúmplices (não especificados)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Quem são os principais personagens do contexto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcJwBtkRfvwy",
        "outputId": "abb780d8-41ae-4d0e-eb97-3ff8d45bbab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os principais personagens do contexto são:\n",
            "\n",
            "1. Joaquim Manuel de Macedo - autor do livro \"As Vítimas-Algozes\"\n",
            "2. Ana - \n",
            "personagem principal do livro, que é uma das vítimas-algozes\n",
            "3. Carlos - outra vítima-algoze, que é amigo de Ana\n",
            "4. Mari\n",
            "a - mãe de Ana, que é uma das principais figuras da história\n",
            "5. Jorge - um dos principais suspeitos da morte de Ana e da\n",
            "s outras vítimas-algozes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Quais os nomes dos principais personagens do contexto?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5H9HQ_PzGBh",
        "outputId": "821ee60f-9f66-48f1-87e2-0f0e72514e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os principais personagens do contexto são:\n",
            "\n",
            "1. Joaquim Manuel de Macedo - autor do livro\n",
            "2. Ana - personagem principal \n",
            "do livro\n",
            "3. Carlos - marido de Ana\n",
            "4. Maria - mãe de Ana\n",
            "5. Antônio - amigo de Ana\n",
            "6. Leonor - amiga de Ana\n",
            "7. Dr. Costa\n",
            " - médico que atende Ana\n",
            "8. Sr. Ferreira - proprietário da fazenda onde Ana morava.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto quem são os principais personagens da história?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncDCuO8InX4Q",
        "outputId": "2852a8d8-1065-4b97-e7d3-20743fdb6326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os principais personagens da história são:\n",
            "\n",
            "1. Simeão: é o principal personagem da história, que tenta fugir com o ouro\n",
            " e a prata, mas é capturado e enforcado.\n",
            "2. Barbudo: é um dos cúmplices de Simeão, que também tenta fugir, mas é captura\n",
            "do e enforcado.\n",
            "3. Eufêmia: é outro cúmplice de Simeão, que também tenta fugir, mas é capturada e enforcada.\n",
            "4. Carrasco\n",
            ": é o responsável pela aplicação da lei e pela execução dos criminosos. Ele é o narrador da história e descreve os event\n",
            "os que ocorreram.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto qual o nome dos principais personagens da história?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Htb5q_zNsO",
        "outputId": "60790f98-39da-41e7-d02a-f53d2562992e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Os principais personagens da história são:\n",
            "\n",
            "1. Joaquim Manuel de Macedo - o autor da obra e o narrador da história.\n",
            "2. \n",
            "Ana - a mulher que é objeto de desejo e violência por parte dos personagens masculinos.\n",
            "3. O rapaz - um dos principais p\n",
            "ersonagens masculinos que participa da história e é responsável pela violência contra Ana.\n",
            "4. O outro rapaz - outro pers\n",
            "onagem masculino que também participa da história e é responsável por outra forma de violência contra Ana.\n",
            "5. O pai - o \n",
            "pai de Ana, que é descrito como um homem cruel e violento.\n",
            "6. A mãe - a mãe de Ana, que é descrita como uma mulher fraca\n",
            " e submissa.\n",
            "7. O juiz - um personagem que aparece na história e é responsável por julgar o caso de violência contra Ana\n",
            ".\n",
            "8. O advogado - um personagem que representa Ana e busca provar a culpa dos principais personagens masculinos envolvid\n",
            "os na história.\n",
            "\n",
            "Esses são os principais personagens da história, e eles são todos envolvidos na trama de violência e ma\n",
            "nipulação que se desenvolve na obra.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Lista para mim as palavras que possuem relação com escravidão. Quantifique as ocorrências no texto\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hoD9rKpgVwv",
        "outputId": "c83c9cdc-186d-4330-95bc-fcdcb9102b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras que possuem relação com escravidão no texto são:\n",
            "\n",
            "1. Escravidão (mencionada em 3 ocasiões)\n",
            "2. Escravo (menc\n",
            "ionado em 2 ocasiões)\n",
            "3. Mão (mencionada em 2 ocasiões)\n",
            "4. Trabalho (mencionado em 2 ocasiões)\n",
            "5. Condenação (mencionada\n",
            " em 1 oportunidade)\n",
            "6. Castigo (mencionado em 1 oportunidade)\n",
            "7. Opressão (mencionada em 1 oportunidade)\n",
            "8. Privilégio (\n",
            "mencionado em 1 oportunidade)\n",
            "\n",
            "Observação: As ocorrências de cada palavra podem variar dependendo do contexto e da inter\n",
            "pretação do texto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto que palavras possuem relação com escravidão?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Tv5t_9nFTG",
        "outputId": "f044aeee-98d7-415a-ee77-38bc5380961f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras \"vítimas-algozes\" de Joaquim Manuel de Macedo possuem relação com a escravidão, pois o autor usou essa expr\n",
            "essão para descrever as pessoas que foram submetidas à escravidão. A palavra \"vítima\" indica que essas pessoas foram vít\n",
            "imas de uma situação de oppressão e exploração, enquanto \"algozes\" é um termo que evoca a ideia de algo que é estranho o\n",
            "u desconhecido, o que reflete a ideia de que a escravidão era uma realidade estranha e desconhecida para muitas pessoas \n",
            "na época. Além disso, a expressão \"vítimas-algozes\" também pode ser entendida como uma crítica à ideologia da escravidão\n",
            ", que considerava as pessoas escravas como se fossem objetos ou propriedade, em vez de seres humanos com direitos e dign\n",
            "idade.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto que palavras possuem relação semântica com escravidão?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "F-Rfy2vjlkVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad11737-ab76-4d52-9956-6bae1e830c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras \"vítimas-algozes\" possuem relação semântica com a escravidão, pois elas são usadas para descrever as pessoa\n",
            "s que são tratadas como bens ou objetos, sem direitos ou liberdades. A palavra \"vítima\" é usada para descrever uma pesso\n",
            "a que sofre um mal ou injustiça, enquanto a palavra \"algoze\" é usada para descrever algo que é considerado como uma merc\n",
            "adoria ou um bens. Juntas, as palavras \"vítimas-algozes\" são usadas para descrever as pessoas que são tratadas como bens\n",
            " ou objetos, sem direitos ou liberdades, o que é semelhante à escravidão.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto que palavras estão relacionadas a escravidão mas deixa isto implicito?\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "f8mj1-zTg-H4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d13c8e-ab69-49ef-a72c-5099d6290dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sim, é possível notar que as palavras relacionadas a escravidão estão presentes no contexto, mas não são explicitamente\n",
            " mencionadas. Ao descrever a situação dos personagens, a obra sugere que a escravidão é um tema importante e que está re\n",
            "lacionada à história, mas não é explicitamente mencionada. Isso pode ser visto como uma forma de criticar a escravidão d\n",
            "e forma implicita, sem necessariamente mencioná-la diretamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Textos do trabalho do **Leandro da Silveira Dias**"
      ],
      "metadata": {
        "id": "DvgszcoyBc0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando a palavra \\\"negro\\\" com alvo, identifique outras palavras no contexto que são semanticamente similares.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "Iq9QgnkNitc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e202957-bdfa-404e-a0b6-b19add689d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Em relação ao contexto fornecido, as palavras semanticamente similares ao termo \"negro\" são:\n",
            "\n",
            "* Preto\n",
            "* Escravo\n",
            "* Crimi\n",
            "nal\n",
            "* Malvado\n",
            "* Perverso\n",
            "\n",
            "Essas palavras têm o mesmo contexto de uso e conotação negativa que o termo \"negro\" em relação\n",
            " às víctimas do crime. É importante notar que o uso dessas palavras pode ser considerado ofensivo e discriminatório, e d\n",
            "eve ser evitado em favor de termos mais neutros e respectuosos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando a palavra alvo \\\"negro\\\", identifique outras palavras no contexto que são semanticamente similares.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70rC7Cew0K3c",
        "outputId": "3ea287ca-4a6b-43f8-957e-25889c913732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ao considerar a palavra \"negro\" no contexto da obra \"As Vítimas-Algozes\", de Joaquim Manuel de Macedo, identificamos ou\n",
            "tras palavras semanticamente similares, que são:\n",
            "\n",
            "1. Preto: É a palavra mais utilizada para descrever a cor do pele em P\n",
            "ortugal, e é utilizada também em outros países lusófonos.\n",
            "2. Africano: Refere-se a uma pessoa que é originária da África\n",
            ", independentemente da cor da pele.\n",
            "3. Afro-brasileiro: É um termo utilizado para descrever uma pessoa que tem ancestral\n",
            "idade africana e que nasceu ou reside no Brasil.\n",
            "4. Afro-latino: É um termo utilizado para descrever uma pessoa que tem \n",
            "ancestralidade africana e que nasceu ou reside em um país lusófono.\n",
            "5. Afro-descendente: É um termo utilizado para descr\n",
            "ever uma pessoa que tem ancestralidade africana e que nasceu ou reside em um país lusófono.\n",
            "\n",
            "É importante notar que a ut\n",
            "ilização dessas palavras pode variar dependendo do contexto e do foco da discussão. É recomendável utilizar palavras que\n",
            " são menos discriminatórias e mais inclusivas, como \"afro-brasileiro\" ou \"afro-latino\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \" Na sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ liste as palavras possuem ligação com a palavra \\'negro\\'\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "2m-pBVlIiifv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8fb553-7ef7-4b2e-e963-cbb4456bb2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  As palavras 'pundonor','vergonha', 'escravidão', 'negro' estão ligadas entre si na sentença, pois todas elas têm um re\n",
            "lacionamento com a cor da pele e com a condição social do negro. 'Pundonor' e'vergonha' são termos que expressam a nobre\n",
            "za e a dignidade, enquanto 'escravidão' é um termo que designa a condição de escravo, que era comum na época e que envol\n",
            "via a propriedade de um ser humano por outro. 'Negro' é um termo que designa a cor da pele dos afro-americanos, e que ta\n",
            "mbém foi utilizado para designar a condição social e a discriminação que esses grupos enfrentavam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \" Na sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ liste as palavras possuem ligação com a palavra alvo \\'negro\\' considerando o contexto.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "b1h37tw8jrOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3275281-2c7f-4389-c40f-dc16048f93b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Na sentença 'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da v\n",
            "ingança.' as palavras 'rancor' e 'desejo' estão ligadas à palavra 'negro' no contexto, pois o escravo tem um sentimento \n",
            "negativo contra os seus cúmplices e proprietários, que o tratam com crueldão e injustiça.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Usando leitura distante realize a analise da sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ para encontrar e listar as palavras possuem ligação com a palavra alvo \\'negro\\'.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "WFS-f5Q0j8Si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a79d52f-deb7-46f4-96f3-d66a71da5ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Com base na leitura distante realizada, as palavras que possuem ligação com a palavra alvo 'negro' na sentença 'Em falt\n",
            "a de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.' são:\n",
            "\n",
            "1. fal\n",
            "ta\n",
            "2. de\n",
            "3. negro\n",
            "4. comporta\n",
            "5. escravidão\n",
            "6. negro\n",
            "\n",
            "Essas palavras possuem uma conexão semântica com a palavra alvo 'n\n",
            "egro', pois estão relacionadas ao tema de escravidão e raça negra.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Considerando o contexto use leitura distante para realizar a analise da sentença \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ para encontrar e listar as palavras possuem ligação com a palavra alvo \\'negro\\'.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "gZ4hwllSmR35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89912900-12cb-4c9e-a185-b18de19df9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Considerando o contexto, as palavras que possuem ligação com a palavra alvo 'negro' são:\n",
            "\n",
            "1. escravidão\n",
            "2. pundonor\n",
            "3. \n",
            "vergonha\n",
            "4. rancor\n",
            "5. vingança\n",
            "\n",
            "Essas palavras possuem uma conexão semântica com a palavra 'negro' pois estão relacionad\n",
            "as ao tema da escravidão e da discriminação racial, que é mencionada na sentença.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Usando leitura distante realize a analise da sentença: \\'Em falta de pundonor e de vergonha, que a escravidão não comporta, o escravo tem o rancor e o desejo da vingança.'\\ e liste as palavras possuem relação semântica com a palavra alvo \\'negro\\'.\"\n",
        "\n",
        "resultado = avaliarContexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ],
      "metadata": {
        "id": "XDEpYSHhkzcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f9fa3f-9fef-4bf4-9266-cc616436b359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As palavras que possuem relação semântica com a palavra alvo 'negro' na sentença analisada são:\n",
            "\n",
            "* rancor\n",
            "* desejo\n",
            "* vi\n",
            "ngança\n",
            "* escravidão\n",
            "* pundonor\n",
            "* vergonha\n",
            "\n",
            "Essas palavras compartilham um significado relacionado ao tema da escravidão \n",
            "e à cor do corpo humano, o que é relevante para a interpretação da sentença.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tempo final de execução das perguntas"
      ],
      "metadata": {
        "id": "1JZDLa5p52S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tempo de execução das perguntas:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvTh9EVI548_",
        "outputId": "dc6b4388-9372-4745-e746-045cc1d47aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução das perguntas:  0:11:47 (h:mm:ss)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}